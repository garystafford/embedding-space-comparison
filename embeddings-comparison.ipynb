{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd8700c",
   "metadata": {},
   "source": [
    "# Text Embedding Comparison\n",
    "\n",
    "The Notebook creates and visualizes 200 text embeddings at 512 dimensions each, projected into 2D for visualization, across four popular open weight text embedding models from Google, Qwen, IBM, and Tencent. Even with identical inputs and dimensionality, each model induces its own embedding space—with different clusters, separations, and neighborhood relationships—which is why production systems need explicit embedding‑model versioning and a full re‑embedding plus re‑indexing step whenever the underlying model changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a63948",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820055c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pip -Uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6786118",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt -Uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc8d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Disable tokenizers parallelism warnings in notebook contexts\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5597b604",
   "metadata": {},
   "source": [
    "## Authenticate with Hugging Face\n",
    "\n",
    "**IMPORTANT: Complete these steps in order:**\n",
    "\n",
    "1. **Request model access**: Visit https://huggingface.co/google/embeddinggemma-300m and click \"Request access to this model\" (requires a free Hugging Face account)\n",
    "2. **Wait for approval**: Access is usually granted immediately or within a few minutes\n",
    "3. **Get your token**: Go to https://huggingface.co/settings/tokens and create a new token (read permission is sufficient)\n",
    "4. **Run the login cell below**: Execute the next cell and paste your token in the text box that appears\n",
    "5. **Verify login**: Run the verification cell to confirm you're authenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae23e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# Login to Hugging Face (this will show a widget for entering your token)\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6efc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify authentication status\n",
    "from huggingface_hub import whoami\n",
    "\n",
    "try:\n",
    "    user_info = whoami()\n",
    "    print(f\"✓ Successfully logged in as: {user_info['name']}\")\n",
    "    print(f\"✓ Authentication token is valid\")\n",
    "except Exception as e:\n",
    "    print(\"✗ Not logged in or token is invalid\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07be16f4",
   "metadata": {},
   "source": [
    "## Load Quotes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb414735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def load_all_quotes(file_path):\n",
    "    quotes = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            quote = json.loads(line)\n",
    "            quotes.append(quote[\"inputs\"])\n",
    "    return quotes\n",
    "\n",
    "\n",
    "file_path = \"quotes/quotes_200.jsonl\"\n",
    "quotes = load_all_quotes(file_path)\n",
    "print(f\"Total number of quotes: {len(quotes)}\")\n",
    "print(f\"First quote in list: {quotes[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88428ca9",
   "metadata": {},
   "source": [
    "## Common Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada52d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def compute_similarity_test(model: SentenceTransformer) -> Tensor:\n",
    "    \"\"\"Compute the similarity between queries and answers using the given model.\n",
    "\n",
    "    Args:\n",
    "        model (SentenceTransformer): The sentence transformer model to use for encoding and similarity computation.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: A tensor containing the similarity scores between each query and answer.\n",
    "    \"\"\"\n",
    "    # The queries and quotes to embed\n",
    "    queries = [\n",
    "        \"What is the capital of China?\",\n",
    "        \"Explain gravity\",\n",
    "    ]\n",
    "    answers = [\n",
    "        \"The capital of China is Beijing.\",\n",
    "        \"Gravity is a force that attracts two bodies towards each other. It gives weight to physical objects and is responsible for the movement of planets around the sun.\",\n",
    "    ]\n",
    "\n",
    "    # Encode the queries and quotes. Note that queries benefit from using a prompt\n",
    "    # Here we use the prompt called \"query\" stored under `model.prompts`, but you can\n",
    "    # also pass your own prompt via the `prompt` argument\n",
    "    query_embeddings = model.encode_query(queries, prompt_name=\"query\")\n",
    "    quote_embeddings = model.encode_document(answers)\n",
    "\n",
    "    # Compute the (cosine) similarity between the query and quote embeddings\n",
    "    similarity = model.similarity(query_embeddings, quote_embeddings)\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7de7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ndarray\n",
    "\n",
    "\n",
    "def generate_embeddings(model: SentenceTransformer, quotes: list[str], dimensions: int=512) -> ndarray:\n",
    "    \"\"\"Embed a list of quotes using the given model and measure the time taken.\n",
    "\n",
    "    Args:\n",
    "        model (SentenceTransformer): The sentence transformer model to use for encoding.\n",
    "        quotes (list[str]): A list of quotes to embed.\n",
    "    \"\"\"\n",
    "    import time\n",
    "\n",
    "    start_time = time.time()\n",
    "    quote_embeddings = model.encode(\n",
    "        quotes,\n",
    "        batch_size=32,\n",
    "        show_progress_bar=True,\n",
    "        truncate_dim=dimensions,  # <- desired output dim\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Time taken: {end_time - start_time} seconds\")\n",
    "    print(f\"Time per embedding: {(end_time - start_time) / len(quotes)} seconds\")\n",
    "\n",
    "    return quote_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f9d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def save_embeddings(quote_embeddings: ndarray, file_name: str) -> str:\n",
    "    \"\"\"Save the quote embeddings to a file.\n",
    "\n",
    "    Args:\n",
    "        quote_embeddings (ndarray): The quote embeddings to save.\n",
    "        file_name (str): The name of the file to save the embeddings to.\n",
    "\n",
    "    Returns:\n",
    "        str: The path to the saved embeddings file.\n",
    "    \"\"\"\n",
    "    embeddings_path = os.path.join(\"embeddings\", file_name)\n",
    "    np.save(embeddings_path, quote_embeddings)\n",
    "\n",
    "    return embeddings_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aqzundcoid7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings_dimension_test(quote_embeddings: ndarray, file_name: str) -> str:\n",
    "    \"\"\"Save the quote embeddings to a file in the dimension_tests folder.\n",
    "\n",
    "    Args:\n",
    "        quote_embeddings (ndarray): The quote embeddings to save.\n",
    "        file_name (str): The name of the file to save the embeddings to.\n",
    "\n",
    "    Returns:\n",
    "        str: The path to the saved embeddings file.\n",
    "    \"\"\"\n",
    "    embeddings_path = os.path.join(\"dimension_tests\", file_name)\n",
    "    os.makedirs(\"dimension_tests\", exist_ok=True)\n",
    "    np.save(embeddings_path, quote_embeddings)\n",
    "\n",
    "    return embeddings_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dticwl6vl8u",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings_multi_dimension(\n",
    "    model: SentenceTransformer,\n",
    "    model_name: str,\n",
    "    quotes: list[str],\n",
    "    dimensions: list[int] = [128, 256, 512, 768],\n",
    ") -> dict[int, str]:\n",
    "    \"\"\"Generate embeddings at multiple dimensions and save them to dimension_tests folder.\n",
    "\n",
    "    Args:\n",
    "        model (SentenceTransformer): The sentence transformer model to use for encoding.\n",
    "        model_name (str): The name of the model (used for file naming).\n",
    "        quotes (list[str]): A list of quotes to embed.\n",
    "        dimensions (list[int]): List of dimension sizes to generate embeddings for.\n",
    "\n",
    "    Returns:\n",
    "        dict[int, str]: Dictionary mapping dimension sizes to file paths.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    print(f\"Generating embeddings for model: {model_name}\")\n",
    "    print(f\"Dimensions to test: {dimensions}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for dim in dimensions:\n",
    "        print(f\"\\nProcessing dimension: {dim}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Generate embeddings at this dimension\n",
    "        embeddings = generate_embeddings(model, quotes, dimensions=dim)\n",
    "        \n",
    "        # Save embeddings\n",
    "        file_name = f\"{model_name}-{dim}.npy\"\n",
    "        file_path = save_embeddings_dimension_test(embeddings, file_name)\n",
    "        \n",
    "        print(f\"Saved to: {file_path}\")\n",
    "        results[dim] = file_path\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"Completed! Generated embeddings for {len(dimensions)} dimensions\")\n",
    "    print(f\"All files saved to: dimension_tests/\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f818f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(embeddings_path: str) -> ndarray:\n",
    "    \"\"\"Load embeddings from a file.\n",
    "\n",
    "    Args:\n",
    "        embeddings_path (str): Path to the file containing the saved embeddings.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: The loaded embeddings as a NumPy array.\n",
    "    \"\"\"\n",
    "    embeddings = np.load(embeddings_path)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c49959c",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8988bdc",
   "metadata": {},
   "source": [
    "### Model 1: EmbeddingGemma\n",
    "\n",
    "`google/embeddinggemma-300m`\n",
    "\n",
    "https://huggingface.co/google/embeddinggemma-300m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516d90f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "google_model = SentenceTransformer(\"google/embeddinggemma-300m\")\n",
    "print(f\"Model loaded: {google_model.model_card_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95282b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test inference with queries and answers\n",
    "similarities = compute_similarity_test(google_model)\n",
    "print(f\"Similarities: {similarities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b63ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the quotes\n",
    "embeddings = generate_embeddings(google_model, quotes, 512)\n",
    "print(f\"Shape: {embeddings.shape}\")  # (200, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbd94e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the quote embeddings to a file for later use\n",
    "embeddings_path = save_embeddings(embeddings, \"google-embedding-gemma-300m-512.npy\")\n",
    "print(f\"Embeddings saved to: {embeddings_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16083a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the quote embeddings from the file\n",
    "loaded_embeddings = load_embeddings(embeddings_path)\n",
    "print(f\"Shape: {loaded_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ac7a1",
   "metadata": {},
   "source": [
    "### Model 2: Qwen3 Embedding 0.6B\n",
    "\n",
    "`Qwen/Qwen3-Embedding-0.6B`\n",
    "\n",
    "https://huggingface.co/Qwen/Qwen3-Embedding-0.6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f927fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "qwen_model = SentenceTransformer(\"Qwen/Qwen3-Embedding-0.6B\")\n",
    "print(f\"Model loaded: {qwen_model.model_card_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38619d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test inference with queries and answers\n",
    "similarities = compute_similarity_test(qwen_model)\n",
    "print(f\"Similarities: {similarities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af91186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the quotes\n",
    "embeddings = generate_embeddings(qwen_model, quotes, 512)\n",
    "print(f\"Shape: {embeddings.shape}\")  # (200, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538b72a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the quote embeddings to a file for later use\n",
    "embeddings_path = save_embeddings(embeddings, \"qwen-qwen3-embedding-0.6b-512.npy\")\n",
    "print(f\"Embeddings saved to: {embeddings_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7ea664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the quote embeddings from the file\n",
    "loaded_embeddings = load_embeddings(embeddings_path)\n",
    "print(f\"Shape: {loaded_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42079f81",
   "metadata": {},
   "source": [
    "### Model 3: IBM Granite Embedding 125m English\n",
    "\n",
    "`ibm-granite/granite-embedding-125m-english`\n",
    "\n",
    "https://huggingface.co/ibm-granite/granite-embedding-125m-english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4000064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "ibm_model = SentenceTransformer(\"ibm-granite/granite-embedding-125m-english\")\n",
    "print(f\"Model loaded: {ibm_model.model_card_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d6b826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test inference with queries and answers\n",
    "similarities = compute_similarity_test(ibm_model)\n",
    "print(f\"Similarities: {similarities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f68b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the quotes\n",
    "embeddings = generate_embeddings(ibm_model, quotes, 512)\n",
    "print(f\"Shape: {embeddings.shape}\")  # (200, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0815ce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the quote embeddings to a file for later use\n",
    "embeddings_path = save_embeddings(\n",
    "    embeddings, \"ibm-granite-embedding-125m-english-512.npy\"\n",
    ")\n",
    "print(f\"Embeddings saved to: {embeddings_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba4f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the quote embeddings from the file\n",
    "loaded_embeddings = load_embeddings(embeddings_path)\n",
    "print(f\"Shape: {loaded_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bbf694",
   "metadata": {},
   "source": [
    "### Model 4: TencentBAC Conan Embedding v1\n",
    "\n",
    "`TencentBAC/Conan-embedding-v1`\n",
    "\n",
    "https://huggingface.co/TencentBAC/Conan-embedding-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69b748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "tencent_model = SentenceTransformer(\"TencentBAC/Conan-embedding-v1\")\n",
    "print(f\"Model loaded: {tencent_model.model_card_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test inference with queries and answers\n",
    "similarities = compute_similarity_test(tencent_model)\n",
    "print(f\"Similarities: {similarities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a839dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the quotes\n",
    "embeddings = generate_embeddings(tencent_model, quotes, 512)\n",
    "print(f\"Shape: {embeddings.shape}\")  # (200, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a60cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the quote embeddings to a file for later use\n",
    "embeddings_path = save_embeddings(embeddings, \"tencentbac-conan-embedding-v1-512.npy\")\n",
    "print(f\"Embeddings saved to: {embeddings_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8880fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the quote embeddings from the file\n",
    "loaded_embeddings = load_embeddings(embeddings_path)\n",
    "print(f\"Shape: {loaded_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7sba3ipzzbk",
   "metadata": {},
   "source": [
    "## Visualization Methods\n",
    "\n",
    "**`normalize_embeddings()`**\n",
    "- L2 normalizes embeddings to unit length\n",
    "- Standardizes to zero mean and unit variance\n",
    "- Ensures all models are on comparable scales\n",
    "\n",
    "**`visualize_multiple_embeddings_improved()`**\n",
    "- Normalizes each model's embeddings separately before combining\n",
    "- Reports PCA explained variance ratio\n",
    "- Supports both PCA and t-SNE\n",
    "- Includes hover text with quote content\n",
    "- Better for direct comparison when normalization is appropriate\n",
    "\n",
    "**`visualize_embeddings_separately()`**\n",
    "- Applies PCA/t-SNE independently to each model\n",
    "- Shows true structure of each embedding space\n",
    "- No cross-contamination between models\n",
    "- Side-by-side subplots for comparison\n",
    "- Better for understanding individual model characteristics\n",
    "\n",
    "### When to Use Which:\n",
    "- **Separate visualization** (`visualize_embeddings_separately`): Best for understanding each model's embedding space structure independently\n",
    "- **Combined normalized** (`visualize_multiple_embeddings_improved`): Best for direct comparison when you want to see relative positions across models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f836aa",
   "metadata": {},
   "source": [
    "### Visualization Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13415129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xnicusv9aar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_embeddings(embeddings: ndarray) -> ndarray:\n",
    "    \"\"\"Normalize embeddings using L2 normalization followed by standardization.\n",
    "\n",
    "    This ensures embeddings from different models are on comparable scales:\n",
    "    1. L2 normalization: Scale each embedding vector to unit length\n",
    "    2. Standardization: Zero mean and unit variance per dimension\n",
    "\n",
    "    Args:\n",
    "        embeddings (ndarray): The embeddings to normalize (shape: [n_samples, n_dimensions])\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Normalized embeddings with the same shape\n",
    "    \"\"\"\n",
    "    # Step 1: L2 normalize each embedding vector to unit length\n",
    "    # This makes all vectors lie on a hypersphere\n",
    "    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    # Avoid division by zero\n",
    "    norms = np.where(norms == 0, 1, norms)\n",
    "    l2_normalized = embeddings / norms\n",
    "\n",
    "    # Step 2: Standardize to zero mean and unit variance per dimension\n",
    "    # This ensures different models have comparable variance structures\n",
    "    mean = l2_normalized.mean(axis=0)\n",
    "    std = l2_normalized.std(axis=0)\n",
    "    # Avoid division by zero for constant dimensions\n",
    "    std = np.where(std == 0, 1, std)\n",
    "    standardized = (l2_normalized - mean) / std\n",
    "\n",
    "    return standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7xbx8w7kac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_multiple_embeddings_improved(\n",
    "    embeddings_list: list[ndarray],\n",
    "    model_names: list[str],\n",
    "    quotes: list[str] = None,\n",
    "    method: str = \"pca\",\n",
    "):\n",
    "    \"\"\"Visualize multiple sets of embeddings in 2D space with proper normalization.\n",
    "\n",
    "    This function addresses methodological issues by:\n",
    "    1. Normalizing each model's embeddings separately before combining\n",
    "    2. Reporting explained variance for PCA\n",
    "    3. Supporting both PCA and t-SNE\n",
    "    4. Adding hover text with quote content\n",
    "\n",
    "    Args:\n",
    "        embeddings_list (list[ndarray]): A list of embeddings to visualize.\n",
    "        model_names (list[str]): A list of model names corresponding to the embeddings.\n",
    "        quotes (list[str], optional): Original quote texts for hover display.\n",
    "        method (str): Dimensionality reduction method - \"pca\" or \"tsne\"\n",
    "    \"\"\"\n",
    "    print(\"Normalizing embeddings for each model separately...\")\n",
    "    normalized_embeddings = []\n",
    "    for i, emb in enumerate(embeddings_list):\n",
    "        norm_emb = normalize_embeddings(emb)\n",
    "        normalized_embeddings.append(norm_emb)\n",
    "        print(f\"  {model_names[i]}: normalized {emb.shape[0]} embeddings\")\n",
    "\n",
    "    # Combine normalized embeddings\n",
    "    combined_embeddings = np.vstack(normalized_embeddings)\n",
    "    print(f\"\\nCombined shape: {combined_embeddings.shape}\")\n",
    "\n",
    "    # Apply dimensionality reduction\n",
    "    if method.lower() == \"pca\":\n",
    "        reducer = PCA(n_components=2)\n",
    "        reduced_embeddings = reducer.fit_transform(combined_embeddings)\n",
    "\n",
    "        # Report explained variance - critical for understanding information loss\n",
    "        print(f\"\\nPCA Explained Variance:\")\n",
    "        print(f\"  PC1: {reducer.explained_variance_ratio_[0]:.2%}\")\n",
    "        print(f\"  PC2: {reducer.explained_variance_ratio_[1]:.2%}\")\n",
    "        print(f\"  Total: {reducer.explained_variance_ratio_.sum():.2%}\")\n",
    "\n",
    "        axis_labels = {\"x\": \"Principal Component 1\", \"y\": \"Principal Component 2\"}\n",
    "        title_method = \"PCA\"\n",
    "    elif method.lower() == \"tsne\":\n",
    "\n",
    "        print(\"\\nApplying t-SNE (this may take a moment)...\")\n",
    "        reducer = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "        reduced_embeddings = reducer.fit_transform(combined_embeddings)\n",
    "        axis_labels = {\"x\": \"t-SNE Dimension 1\", \"y\": \"t-SNE Dimension 2\"}\n",
    "        title_method = \"t-SNE\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}. Use 'pca' or 'tsne'\")\n",
    "\n",
    "    # Create a DataFrame for Plotly\n",
    "    df = pd.DataFrame(reduced_embeddings, columns=[\"dim1\", \"dim2\"])\n",
    "    df[\"Model\"] = np.repeat(model_names, [emb.shape[0] for emb in embeddings_list])\n",
    "\n",
    "    # Add quote text for hover if provided\n",
    "    if quotes is not None:\n",
    "        # Repeat quotes for each model\n",
    "        all_quotes = quotes * len(embeddings_list)\n",
    "        # Truncate quotes to 50 characters for hover display\n",
    "        df[\"Quote\"] = [q[:50] + \"...\" if len(q) > 50 else q for q in all_quotes]\n",
    "        hover_data = {\"Quote\": True, \"Model\": True, \"dim1\": \":.3f\", \"dim2\": \":.3f\"}\n",
    "    else:\n",
    "        hover_data = {\"Model\": True, \"dim1\": \":.3f\", \"dim2\": \":.3f\"}\n",
    "\n",
    "    # Create scatter plot\n",
    "    fig = px.scatter(\n",
    "        df,\n",
    "        x=\"dim1\",\n",
    "        y=\"dim2\",\n",
    "        color=\"Model\",\n",
    "        color_discrete_sequence=px.colors.qualitative.Vivid,\n",
    "        title=f\"2D Visualization of Embeddings ({title_method}, Normalized)\",\n",
    "        labels={\"dim1\": axis_labels[\"x\"], \"dim2\": axis_labels[\"y\"]},\n",
    "        hover_data=hover_data,\n",
    "    )\n",
    "\n",
    "    fig.update_traces(marker=dict(size=6, opacity=0.7))\n",
    "\n",
    "    # Make title bold and centered, set Arial font, and increase resolution\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            \"text\": f\"<b>2D Visualization of Embeddings ({title_method}, Normalized)</b>\",\n",
    "            \"x\": 0.5,\n",
    "            \"xanchor\": \"center\",\n",
    "            \"font\": {\"size\": 18, \"family\": \"Arial, sans-serif\"},\n",
    "        },\n",
    "        font={\"family\": \"Arial, sans-serif\", \"size\": 12},\n",
    "        width=1200,\n",
    "        height=600,\n",
    "    )\n",
    "\n",
    "    # Show with high resolution\n",
    "    fig.show(config={\"toImageButtonOptions\": {\"format\": \"png\", \"scale\": 3}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j1d15doxxbo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_multiple_embeddings_animated(\n",
    "    embeddings_list: list[ndarray],\n",
    "    model_names: list[str],\n",
    "    quotes: list[str] = None,\n",
    "    method: str = \"tsne\",\n",
    "    num_frames: int = 60,\n",
    "    frame_duration: int = 50,\n",
    "    loop: bool = False,\n",
    "    sequential: bool = False,\n",
    "    highlight_quote_idx: int = None,\n",
    "):\n",
    "    \"\"\"Visualize multiple sets of embeddings with animation from origin to final positions.\n",
    "\n",
    "    All markers start at (0, 0) and animate smoothly to their final t-SNE or PCA coordinates.\n",
    "\n",
    "    Args:\n",
    "        embeddings_list (list[ndarray]): A list of embeddings to visualize.\n",
    "        model_names (list[str]): A list of model names corresponding to the embeddings.\n",
    "        quotes (list[str], optional): Original quote texts for hover display.\n",
    "        method (str): Dimensionality reduction method - \"pca\" or \"tsne\"\n",
    "        num_frames (int): Number of animation frames (default: 60)\n",
    "        frame_duration (int): Duration of each frame in milliseconds (default: 50ms)\n",
    "        loop (bool): Whether to loop the animation (default: False)\n",
    "        sequential (bool): If True, animate each model group sequentially instead of all at once\n",
    "        highlight_quote_idx (int): Index of quote to highlight across all models (0-based)\n",
    "    \"\"\"\n",
    "    print(\"Normalizing embeddings for each model separately...\")\n",
    "    normalized_embeddings = []\n",
    "    for i, emb in enumerate(embeddings_list):\n",
    "        norm_emb = normalize_embeddings(emb)\n",
    "        normalized_embeddings.append(norm_emb)\n",
    "        print(f\"  {model_names[i]}: normalized {emb.shape[0]} embeddings\")\n",
    "\n",
    "    # Combine normalized embeddings\n",
    "    combined_embeddings = np.vstack(normalized_embeddings)\n",
    "    print(f\"\\nCombined shape: {combined_embeddings.shape}\")\n",
    "\n",
    "    # Apply dimensionality reduction\n",
    "    if method.lower() == \"pca\":\n",
    "        reducer = PCA(n_components=2)\n",
    "        reduced_embeddings = reducer.fit_transform(combined_embeddings)\n",
    "\n",
    "        print(f\"\\nPCA Explained Variance:\")\n",
    "        print(f\"  PC1: {reducer.explained_variance_ratio_[0]:.2%}\")\n",
    "        print(f\"  PC2: {reducer.explained_variance_ratio_[1]:.2%}\")\n",
    "        print(f\"  Total: {reducer.explained_variance_ratio_.sum():.2%}\")\n",
    "\n",
    "        axis_labels = {\"x\": \"Principal Component 1\", \"y\": \"Principal Component 2\"}\n",
    "        title_method = \"PCA\"\n",
    "    elif method.lower() == \"tsne\":\n",
    "        print(\"\\nApplying t-SNE (this may take a moment)...\")\n",
    "        reducer = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "        reduced_embeddings = reducer.fit_transform(combined_embeddings)\n",
    "        axis_labels = {\"x\": \"t-SNE Dimension 1\", \"y\": \"t-SNE Dimension 2\"}\n",
    "        title_method = \"t-SNE\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}. Use 'pca' or 'tsne'\")\n",
    "\n",
    "    # Create DataFrame with final positions\n",
    "    df = pd.DataFrame(reduced_embeddings, columns=[\"dim1\", \"dim2\"])\n",
    "    df[\"Model\"] = np.repeat(model_names, [emb.shape[0] for emb in embeddings_list])\n",
    "\n",
    "    # Add quote text for hover if provided\n",
    "    if quotes is not None:\n",
    "        all_quotes = quotes * len(embeddings_list)\n",
    "        df[\"Quote\"] = all_quotes\n",
    "\n",
    "    # Calculate axis ranges from final positions with padding\n",
    "    x_min, x_max = df[\"dim1\"].min(), df[\"dim1\"].max()\n",
    "    y_min, y_max = df[\"dim2\"].min(), df[\"dim2\"].max()\n",
    "\n",
    "    # Add 10% padding to ensure all points are visible\n",
    "    x_padding = (x_max - x_min) * 0.1\n",
    "    y_padding = (y_max - y_min) * 0.1\n",
    "    x_range = [x_min - x_padding, x_max + x_padding]\n",
    "    y_range = [y_min - y_padding, y_max + y_padding]\n",
    "\n",
    "    print(f\"Axis ranges: x={x_range}, y={y_range}\")\n",
    "    \n",
    "    if highlight_quote_idx is not None:\n",
    "        print(f\"\\nHighlighting quote #{highlight_quote_idx}: \\\"{quotes[highlight_quote_idx][:60]}...\\\"\")\n",
    "\n",
    "    # Get color mapping for models\n",
    "    colors = px.colors.qualitative.Vivid\n",
    "    color_map = {model: colors[i % len(colors)] for i, model in enumerate(model_names)}\n",
    "\n",
    "    # Helper function to truncate quotes for hover text\n",
    "    def truncate_quote(quote, max_length=50):\n",
    "        \"\"\"Truncate quote to max_length characters and add ellipsis if needed.\"\"\"\n",
    "        if len(quote) <= max_length:\n",
    "            return quote\n",
    "        return quote[:max_length] + \"...\"\n",
    "\n",
    "    # Calculate timing for sequential animation\n",
    "    num_models = len(model_names)\n",
    "    if sequential:\n",
    "        frames_per_model = num_frames // num_models\n",
    "        print(f\"\\nSequential animation: {frames_per_model} frames per model\")\n",
    "    \n",
    "    print(f\"\\nGenerating {num_frames} animation frames...\")\n",
    "\n",
    "    # Create initial frame (all points at origin)\n",
    "    initial_traces = []\n",
    "    for model in model_names:\n",
    "        model_df = df[df[\"Model\"] == model]\n",
    "        \n",
    "        # Separate regular points from highlighted point\n",
    "        if highlight_quote_idx is not None:\n",
    "            regular_mask = [i != highlight_quote_idx for i in range(len(model_df))]\n",
    "            highlight_mask = [i == highlight_quote_idx for i in range(len(model_df))]\n",
    "            \n",
    "            # Regular points\n",
    "            if any(regular_mask):\n",
    "                if quotes is not None:\n",
    "                    hover_text = [\n",
    "                        f\"Quote: {truncate_quote(q)}<br>Model: {model}<br>x: 0.000<br>y: 0.000\"\n",
    "                        for i, q in enumerate(model_df[\"Quote\"]) if regular_mask[i]\n",
    "                    ]\n",
    "                else:\n",
    "                    hover_text = [f\"Model: {model}<br>x: 0.000<br>y: 0.000\"] * sum(regular_mask)\n",
    "\n",
    "                trace = go.Scatter(\n",
    "                    x=[0] * sum(regular_mask),\n",
    "                    y=[0] * sum(regular_mask),\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(size=6, opacity=0.4, color=color_map[model]),\n",
    "                    name=model,\n",
    "                    text=hover_text,\n",
    "                    hovertemplate=\"%{text}<extra></extra>\",\n",
    "                    showlegend=True,\n",
    "                )\n",
    "                initial_traces.append(trace)\n",
    "            \n",
    "            # Highlighted point\n",
    "            if any(highlight_mask):\n",
    "                if quotes is not None:\n",
    "                    hover_text = [f\"HIGHLIGHTED<br>Quote: {truncate_quote(q)}<br>Model: {model}<br>x: 0.000<br>y: 0.000\"\n",
    "                                for i, q in enumerate(model_df[\"Quote\"]) if highlight_mask[i]]\n",
    "                else:\n",
    "                    hover_text = [f\"HIGHLIGHTED<br>Model: {model}<br>x: 0.000<br>y: 0.000\"]\n",
    "\n",
    "                trace = go.Scatter(\n",
    "                    x=[0],\n",
    "                    y=[0],\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(\n",
    "                        size=15,\n",
    "                        opacity=1.0,\n",
    "                        color=color_map[model],\n",
    "                        line=dict(width=2, color='white')\n",
    "                    ),\n",
    "                    name=f\"{model} (highlighted)\",\n",
    "                    text=hover_text,\n",
    "                    hovertemplate=\"%{text}<extra></extra>\",\n",
    "                    showlegend=False,\n",
    "                )\n",
    "                initial_traces.append(trace)\n",
    "        else:\n",
    "            # No highlighting - original behavior\n",
    "            if quotes is not None:\n",
    "                hover_text = [\n",
    "                    f\"Quote: {truncate_quote(q)}<br>Model: {model}<br>x: 0.000<br>y: 0.000\"\n",
    "                    for q in model_df[\"Quote\"]\n",
    "                ]\n",
    "            else:\n",
    "                hover_text = [f\"Model: {model}<br>x: 0.000<br>y: 0.000\"] * len(model_df)\n",
    "\n",
    "            trace = go.Scatter(\n",
    "                x=[0] * len(model_df),\n",
    "                y=[0] * len(model_df),\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=6, opacity=0.4, color=color_map[model]),\n",
    "                name=model,\n",
    "                text=hover_text,\n",
    "                hovertemplate=\"%{text}<extra></extra>\",\n",
    "            )\n",
    "            initial_traces.append(trace)\n",
    "\n",
    "    # Create animation frames\n",
    "    frames = []\n",
    "    for frame_idx in range(num_frames):\n",
    "        frame_traces = []\n",
    "        \n",
    "        for model_idx, model in enumerate(model_names):\n",
    "            model_df = df[df[\"Model\"] == model].reset_index(drop=True)\n",
    "            \n",
    "            if sequential:\n",
    "                # Calculate which model should be animating at this frame\n",
    "                start_frame = model_idx * frames_per_model\n",
    "                end_frame = start_frame + frames_per_model\n",
    "                \n",
    "                if frame_idx < start_frame:\n",
    "                    t = 0.0\n",
    "                elif frame_idx >= end_frame:\n",
    "                    t = 1.0\n",
    "                else:\n",
    "                    t = (frame_idx - start_frame) / frames_per_model\n",
    "            else:\n",
    "                t = frame_idx / (num_frames - 1)\n",
    "            \n",
    "            # Separate regular points from highlighted point\n",
    "            if highlight_quote_idx is not None:\n",
    "                regular_mask = [i != highlight_quote_idx for i in range(len(model_df))]\n",
    "                highlight_mask = [i == highlight_quote_idx for i in range(len(model_df))]\n",
    "                \n",
    "                # Regular points\n",
    "                if any(regular_mask):\n",
    "                    regular_df = model_df[regular_mask]\n",
    "                    x_positions = t * regular_df[\"dim1\"].values\n",
    "                    y_positions = t * regular_df[\"dim2\"].values\n",
    "\n",
    "                    if quotes is not None:\n",
    "                        hover_text = [\n",
    "                            f\"Quote: {truncate_quote(q)}<br>Model: {model}<br>x: {x:.3f}<br>y: {y:.3f}\"\n",
    "                            for q, x, y in zip(regular_df[\"Quote\"], x_positions, y_positions)\n",
    "                        ]\n",
    "                    else:\n",
    "                        hover_text = [\n",
    "                            f\"Model: {model}<br>x: {x:.3f}<br>y: {y:.3f}\"\n",
    "                            for x, y in zip(x_positions, y_positions)\n",
    "                        ]\n",
    "\n",
    "                    trace = go.Scatter(\n",
    "                        x=x_positions,\n",
    "                        y=y_positions,\n",
    "                        mode=\"markers\",\n",
    "                        marker=dict(size=6, opacity=0.4, color=color_map[model]),\n",
    "                        name=model,\n",
    "                        text=hover_text,\n",
    "                        hovertemplate=\"%{text}<extra></extra>\",\n",
    "                        showlegend=True,\n",
    "                    )\n",
    "                    frame_traces.append(trace)\n",
    "                \n",
    "                # Highlighted point\n",
    "                if any(highlight_mask):\n",
    "                    highlight_df = model_df[highlight_mask]\n",
    "                    x_positions = t * highlight_df[\"dim1\"].values\n",
    "                    y_positions = t * highlight_df[\"dim2\"].values\n",
    "\n",
    "                    if quotes is not None:\n",
    "                        hover_text = [f\"HIGHLIGHTED<br>Quote: {truncate_quote(q)}<br>Model: {model}<br>x: {x:.3f}<br>y: {y:.3f}\"\n",
    "                                    for q, x, y in zip(highlight_df[\"Quote\"], x_positions, y_positions)]\n",
    "                    else:\n",
    "                        hover_text = [f\"HIGHLIGHTED<br>Model: {model}<br>x: {x:.3f}<br>y: {y:.3f}\"\n",
    "                                    for x, y in zip(x_positions, y_positions)]\n",
    "\n",
    "                    trace = go.Scatter(\n",
    "                        x=x_positions,\n",
    "                        y=y_positions,\n",
    "                        mode=\"markers\",\n",
    "                        marker=dict(\n",
    "                            size=15,\n",
    "                            opacity=1.0,\n",
    "                            color=color_map[model],\n",
    "                            line=dict(width=2, color='white')\n",
    "                        ),\n",
    "                        name=f\"{model} (highlighted)\",\n",
    "                        text=hover_text,\n",
    "                        hovertemplate=\"%{text}<extra></extra>\",\n",
    "                        showlegend=False,\n",
    "                    )\n",
    "                    frame_traces.append(trace)\n",
    "            else:\n",
    "                # No highlighting - original behavior\n",
    "                x_positions = t * model_df[\"dim1\"].values\n",
    "                y_positions = t * model_df[\"dim2\"].values\n",
    "\n",
    "                if quotes is not None:\n",
    "                    hover_text = [\n",
    "                        f\"Quote: {truncate_quote(q)}<br>Model: {model}<br>x: {x:.3f}<br>y: {y:.3f}\"\n",
    "                        for q, x, y in zip(model_df[\"Quote\"], x_positions, y_positions)\n",
    "                    ]\n",
    "                else:\n",
    "                    hover_text = [\n",
    "                        f\"Model: {model}<br>x: {x:.3f}<br>y: {y:.3f}\"\n",
    "                        for x, y in zip(x_positions, y_positions)\n",
    "                    ]\n",
    "\n",
    "                trace = go.Scatter(\n",
    "                    x=x_positions,\n",
    "                    y=y_positions,\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(size=6, opacity=0.4, color=color_map[model]),\n",
    "                    name=model,\n",
    "                    text=hover_text,\n",
    "                    hovertemplate=\"%{text}<extra></extra>\",\n",
    "                )\n",
    "                frame_traces.append(trace)\n",
    "\n",
    "        frames.append(go.Frame(data=frame_traces, name=str(frame_idx)))\n",
    "\n",
    "    # Create figure with initial frame\n",
    "    fig = go.Figure(data=initial_traces, frames=frames)\n",
    "\n",
    "    # Update layout with animation controls and fixed axis ranges\n",
    "    animation_type = \"Sequential\" if sequential else \"Synchronized\"\n",
    "    \n",
    "    # Prepare annotations list\n",
    "    annotations = []\n",
    "    \n",
    "    # Add annotation explaining highlighted markers if applicable\n",
    "    if highlight_quote_idx is not None and quotes is not None:\n",
    "        annotations.append(\n",
    "            dict(\n",
    "                x=0.02,\n",
    "                y=0.98,\n",
    "                xref=\"paper\",\n",
    "                yref=\"paper\",\n",
    "                text=f\"<b>Larger markers (●):</b> Same text input across all models\",\n",
    "                showarrow=False,\n",
    "                font=dict(size=11, family=\"Arial, sans-serif\", color=\"#333\"),\n",
    "                align=\"left\",\n",
    "                bgcolor=\"rgba(255, 255, 255, 0.85)\",\n",
    "                bordercolor=\"#666\",\n",
    "                borderwidth=1,\n",
    "                borderpad=8,\n",
    "                xanchor=\"left\",\n",
    "                yanchor=\"top\",\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            \"text\": f\"<b>2D Visualization of Embeddings ({title_method}, Normalized)</b>\",\n",
    "            \"x\": 0.5,\n",
    "            \"xanchor\": \"center\",\n",
    "            \"font\": {\"size\": 18, \"family\": \"Arial, sans-serif\"},\n",
    "        },\n",
    "        xaxis={\"title\": axis_labels[\"x\"], \"range\": x_range},\n",
    "        yaxis={\"title\": axis_labels[\"y\"], \"range\": y_range},\n",
    "        font={\"family\": \"Arial, sans-serif\", \"size\": 12},\n",
    "        width=1200,\n",
    "        height=600,\n",
    "        annotations=annotations,\n",
    "        updatemenus=[\n",
    "            {\n",
    "                \"type\": \"buttons\",\n",
    "                \"showactive\": False,\n",
    "                \"buttons\": [\n",
    "                    {\n",
    "                        \"label\": \"Play\",\n",
    "                        \"method\": \"animate\",\n",
    "                        \"args\": [\n",
    "                            None,\n",
    "                            {\n",
    "                                \"frame\": {\"duration\": frame_duration, \"redraw\": True},\n",
    "                                \"fromcurrent\": True,\n",
    "                                \"mode\": \"immediate\" if not loop else \"loop\",\n",
    "                                \"transition\": {\"duration\": 0, \"easing\": \"linear\"},\n",
    "                            },\n",
    "                        ],\n",
    "                    },\n",
    "                    {\n",
    "                        \"label\": \"Pause\",\n",
    "                        \"method\": \"animate\",\n",
    "                        \"args\": [\n",
    "                            [None],\n",
    "                            {\n",
    "                                \"frame\": {\"duration\": 0, \"redraw\": False},\n",
    "                                \"mode\": \"immediate\",\n",
    "                                \"transition\": {\"duration\": 0},\n",
    "                            },\n",
    "                        ],\n",
    "                    },\n",
    "                ],\n",
    "                \"x\": 0.1,\n",
    "                \"y\": 0,\n",
    "                \"xanchor\": \"right\",\n",
    "                \"yanchor\": \"top\",\n",
    "            }\n",
    "        ],\n",
    "        sliders=[\n",
    "            {\n",
    "                \"active\": 0,\n",
    "                \"steps\": [\n",
    "                    {\n",
    "                        \"args\": [\n",
    "                            [str(k)],\n",
    "                            {\n",
    "                                \"frame\": {\"duration\": 0, \"redraw\": True},\n",
    "                                \"mode\": \"immediate\",\n",
    "                                \"transition\": {\"duration\": 0},\n",
    "                            },\n",
    "                        ],\n",
    "                        \"label\": str(k),\n",
    "                        \"method\": \"animate\",\n",
    "                    }\n",
    "                    for k in range(num_frames)\n",
    "                ],\n",
    "                \"x\": 0.1,\n",
    "                \"len\": 0.9,\n",
    "                \"xanchor\": \"left\",\n",
    "                \"y\": 0,\n",
    "                \"yanchor\": \"top\",\n",
    "                \"pad\": {\"b\": 10, \"t\": 50},\n",
    "                \"currentvalue\": {\n",
    "                    \"visible\": True,\n",
    "                    \"prefix\": \"Frame: \",\n",
    "                    \"xanchor\": \"right\",\n",
    "                    \"font\": {\"size\": 14},\n",
    "                },\n",
    "                \"transition\": {\"duration\": 0},\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    print(\"Animation ready!\")\n",
    "    \n",
    "    # Show with high resolution\n",
    "    fig.show(config={\"toImageButtonOptions\": {\"format\": \"png\", \"scale\": 3}})\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ag440vewgla",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings_separately(\n",
    "    embeddings_list: list[ndarray],\n",
    "    model_names: list[str],\n",
    "    quotes: list[str] = None,\n",
    "    method: str = \"pca\",\n",
    "    shared_axes: bool = True,\n",
    "):\n",
    "    \"\"\"Visualize embeddings with separate dimensionality reduction per model.\n",
    "\n",
    "    This approach applies PCA/t-SNE independently to each model's embeddings,\n",
    "    showing the true structure of each embedding space without cross-contamination.\n",
    "    Models are displayed side-by-side in subplots for comparison.\n",
    "\n",
    "    Args:\n",
    "        embeddings_list (list[ndarray]): A list of embeddings to visualize.\n",
    "        model_names (list[str]): A list of model names corresponding to the embeddings.\n",
    "        quotes (list[str], optional): Original quote texts for hover display.\n",
    "        method (str): Dimensionality reduction method - \"pca\" or \"tsne\"\n",
    "        shared_axes (bool): If True, all subplots use the same x/y axis ranges for direct comparison\n",
    "    \"\"\"\n",
    "    n_models = len(embeddings_list)\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=n_models, subplot_titles=model_names, horizontal_spacing=0.05\n",
    "    )\n",
    "\n",
    "    # First pass: compute all reductions and find global ranges if needed\n",
    "    all_reduced = []\n",
    "    all_explained_vars = []\n",
    "\n",
    "    for embeddings in embeddings_list:\n",
    "        # Apply dimensionality reduction independently\n",
    "        if method.lower() == \"pca\":\n",
    "            reducer = PCA(n_components=2)\n",
    "            reduced = reducer.fit_transform(embeddings)\n",
    "            explained_var = reducer.explained_variance_ratio_.sum()\n",
    "            all_explained_vars.append(explained_var)\n",
    "        elif method.lower() == \"tsne\":\n",
    "            reducer = TSNE(n_components=2, random_state=42)\n",
    "            reduced = reducer.fit_transform(embeddings)\n",
    "            all_explained_vars.append(None)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "        all_reduced.append(reduced)\n",
    "\n",
    "    # Compute shared axis ranges if requested\n",
    "    if shared_axes:\n",
    "        all_x = np.concatenate([r[:, 0] for r in all_reduced])\n",
    "        all_y = np.concatenate([r[:, 1] for r in all_reduced])\n",
    "        x_min, x_max = all_x.min(), all_x.max()\n",
    "        y_min, y_max = all_y.min(), all_y.max()\n",
    "        # Add small padding (5%)\n",
    "        x_padding = (x_max - x_min) * 0.05\n",
    "        y_padding = (y_max - y_min) * 0.05\n",
    "        x_range = [x_min - x_padding, x_max + x_padding]\n",
    "        y_range = [y_min - y_padding, y_max + y_padding]\n",
    "\n",
    "    # Second pass: create plots\n",
    "    for i, (reduced, model_name, explained_var) in enumerate(\n",
    "        zip(all_reduced, model_names, all_explained_vars)\n",
    "    ):\n",
    "        # Prepare subtitle with explained variance\n",
    "        if explained_var is not None:\n",
    "            subtitle_suffix = f\"<br>(Explained var: {explained_var:.1%})\"\n",
    "        else:\n",
    "            subtitle_suffix = \"\"\n",
    "\n",
    "        # Prepare hover text with truncated quotes\n",
    "        if quotes is not None:\n",
    "            hover_text = [\n",
    "                f\"Quote: {q[:50]}...\" if len(q) > 50 else f\"Quote: {q}\"\n",
    "                for q in quotes\n",
    "            ]\n",
    "        else:\n",
    "            hover_text = None\n",
    "\n",
    "        # Add scatter trace\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=reduced[:, 0],\n",
    "                y=reduced[:, 1],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=5, opacity=0.6, color=px.colors.qualitative.Vivid[i]),\n",
    "                text=hover_text,\n",
    "                hovertemplate=\"%{text}<br>x: %{x:.3f}<br>y: %{y:.3f}<extra></extra>\",\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=1,\n",
    "            col=i + 1,\n",
    "        )\n",
    "\n",
    "        # Update subplot title with explained variance and font\n",
    "        fig.layout.annotations[i].update(\n",
    "            text=model_name + subtitle_suffix,\n",
    "            font=dict(family=\"Arial, sans-serif\", size=14),\n",
    "        )\n",
    "\n",
    "        # Set axis ranges\n",
    "        if shared_axes:\n",
    "            fig.update_xaxes(range=x_range, row=1, col=i + 1)\n",
    "            fig.update_yaxes(range=y_range, row=1, col=i + 1)\n",
    "\n",
    "    method_name = \"PCA\" if method.lower() == \"pca\" else \"t-SNE\"\n",
    "    axes_note = \" (Shared Axes)\" if shared_axes else \" (Independent Axes)\"\n",
    "\n",
    "    # Make title bold and centered, set Arial font, and increase resolution\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            \"text\": f\"<b>Separate {method_name} per Model{axes_note}</b>\",\n",
    "            \"x\": 0.5,\n",
    "            \"xanchor\": \"center\",\n",
    "            \"font\": {\"size\": 18, \"family\": \"Arial, sans-serif\"},\n",
    "        },\n",
    "        font={\"family\": \"Arial, sans-serif\", \"size\": 12},\n",
    "        width=1600,\n",
    "        height=400,\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    # Show with high resolution\n",
    "    fig.show(config={\"toImageButtonOptions\": {\"format\": \"png\", \"scale\": 3}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacf73fa",
   "metadata": {},
   "source": [
    "### Create Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tj8hy693t7p",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embeddings from all three models\n",
    "embeddings_google = load_embeddings(\"embeddings/google-embedding-gemma-300m-512.npy\")\n",
    "embeddings_qwen = load_embeddings(\"embeddings/qwen-qwen3-embedding-0.6b-512.npy\")\n",
    "embeddings_ibm = load_embeddings(\n",
    "    \"embeddings/ibm-granite-embedding-125m-english-512.npy\"\n",
    ")\n",
    "embeddings_tencent = load_embeddings(\"embeddings/tencentbac-conan-embedding-v1-512.npy\")\n",
    "\n",
    "print(f\"Loaded embeddings:\")\n",
    "print(f\"  Google: {embeddings_google.shape}\")\n",
    "print(f\"  Qwen: {embeddings_qwen.shape}\")\n",
    "print(f\"  IBM: {embeddings_ibm.shape}\")\n",
    "print(f\"  Tencent: {embeddings_tencent.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fg5rxxq0gs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Combined visualization with normalization (PCA)\n",
    "print(\"=\" * 80)\n",
    "print(\"METHOD 1: Combined PCA with Normalization\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "visualize_multiple_embeddings_improved(\n",
    "    [embeddings_google, embeddings_qwen, embeddings_ibm, embeddings_tencent],\n",
    "    [\"Google EmbeddingGemma\", \"Qwen3 Embedding\", \"IBM Granite\", \"Tencent Conan\"],\n",
    "    quotes=quotes,\n",
    "    method=\"pca\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cy5ckixqhmv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Separate PCA per model (shows true structure of each space)\n",
    "print(\"=\" * 80)\n",
    "print(\"METHOD 2: Separate PCA per Model\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Each model gets its own PCA transformation - no cross-contamination\\n\")\n",
    "\n",
    "visualize_embeddings_separately(\n",
    "    [embeddings_google, embeddings_qwen, embeddings_ibm, embeddings_tencent],\n",
    "    [\"Google EmbeddingGemma\", \"Qwen3 Embedding\", \"IBM Granite\", \"Tencent Conan\"],\n",
    "    quotes=quotes,\n",
    "    method=\"pca\",\n",
    "    shared_axes=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lzb6gd7ta7n",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Combined t-SNE with normalization (better for local structure)\n",
    "print(\"=\" * 80)\n",
    "print(\"METHOD 3: Combined t-SNE with Normalization\")\n",
    "print(\"=\" * 80)\n",
    "print(\"t-SNE preserves local structure better than PCA\\n\")\n",
    "\n",
    "visualize_multiple_embeddings_improved(\n",
    "    [embeddings_google, embeddings_qwen, embeddings_ibm, embeddings_tencent],\n",
    "    [\"Google EmbeddingGemma\", \"Qwen3 Embedding\", \"IBM Granite\", \"Tencent Conan\"],\n",
    "    quotes=quotes,\n",
    "    method=\"tsne\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6qnlrtclyjb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Animated combined t-SNE with normalization\n",
    "print(\"=\" * 80)\n",
    "print(\"METHOD 4: Combined t-SNE with Normalization (Sequential)\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Watch as each model group animates from origin (0,0) to their positions, one at a time!\\n\")\n",
    "\n",
    "animated_fig = visualize_multiple_embeddings_animated(\n",
    "    [embeddings_google, embeddings_qwen, embeddings_ibm, embeddings_tencent],\n",
    "    [\"Google EmbeddingGemma\", \"Qwen3 Embedding\", \"IBM Granite\", \"Tencent Conan\"],\n",
    "    quotes=quotes,\n",
    "    method=\"tsne\",\n",
    "    num_frames=120,  # Increased from 60 to 120 for smoother, slower animation\n",
    "    frame_duration=50,\n",
    "    loop=False,\n",
    "    sequential=True,  # Enable sequential animation - one group at a time\n",
    "    highlight_quote_idx=10,  # Highlight same quote across all models\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g0xvzp7o617",
   "metadata": {},
   "source": [
    "### Save Visualizations as High-Resolution PNGs\n",
    "\n",
    "Now let's save all three visualizations as PNG files for external use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z5r0t3zm8o",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_visualization_as_png(\n",
    "    embeddings_list: list[ndarray],\n",
    "    model_names: list[str],\n",
    "    quotes: list[str],\n",
    "    method: str,\n",
    "    filename: str,\n",
    "    viz_type: str = \"combined\",\n",
    "    shared_axes: bool = True,\n",
    "):\n",
    "    \"\"\"Save a visualization as a high-resolution PNG file.\n",
    "\n",
    "    Args:\n",
    "        embeddings_list (list[ndarray]): A list of embeddings to visualize.\n",
    "        model_names (list[str]): A list of model names corresponding to the embeddings.\n",
    "        quotes (list[str]): Original quote texts.\n",
    "        method (str): Dimensionality reduction method - \"pca\" or \"tsne\"\n",
    "        filename (str): Output filename (without extension)\n",
    "        viz_type (str): \"combined\" or \"separate\"\n",
    "        shared_axes (bool): If True and viz_type=\"separate\", use shared axes\n",
    "    \"\"\"\n",
    "\n",
    "    if viz_type == \"combined\":\n",
    "        # Normalize embeddings\n",
    "        normalized_embeddings = []\n",
    "        for emb in embeddings_list:\n",
    "            normalized_embeddings.append(normalize_embeddings(emb))\n",
    "\n",
    "        combined_embeddings = np.vstack(normalized_embeddings)\n",
    "\n",
    "        # Apply dimensionality reduction\n",
    "        if method.lower() == \"pca\":\n",
    "            reducer = PCA(n_components=2)\n",
    "            reduced_embeddings = reducer.fit_transform(combined_embeddings)\n",
    "            axis_labels = {\"x\": \"Principal Component 1\", \"y\": \"Principal Component 2\"}\n",
    "            title_method = \"PCA\"\n",
    "        elif method.lower() == \"tsne\":\n",
    "            reducer = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "            reduced_embeddings = reducer.fit_transform(combined_embeddings)\n",
    "            axis_labels = {\"x\": \"t-SNE Dimension 1\", \"y\": \"t-SNE Dimension 2\"}\n",
    "            title_method = \"t-SNE\"\n",
    "\n",
    "        df = pd.DataFrame(reduced_embeddings, columns=[\"dim1\", \"dim2\"])\n",
    "        df[\"Model\"] = np.repeat(model_names, [emb.shape[0] for emb in embeddings_list])\n",
    "        all_quotes = quotes * len(embeddings_list)\n",
    "        # Truncate quotes to 50 characters for hover display\n",
    "        df[\"Quote\"] = [q[:50] + \"...\" if len(q) > 50 else q for q in all_quotes]\n",
    "\n",
    "        fig = px.scatter(\n",
    "            df,\n",
    "            x=\"dim1\",\n",
    "            y=\"dim2\",\n",
    "            color=\"Model\",\n",
    "            color_discrete_sequence=px.colors.qualitative.Vivid,\n",
    "            labels={\"dim1\": axis_labels[\"x\"], \"dim2\": axis_labels[\"y\"]},\n",
    "            hover_data={\"Quote\": True, \"Model\": True, \"dim1\": \":.3f\", \"dim2\": \":.3f\"},\n",
    "        )\n",
    "\n",
    "        fig.update_traces(marker=dict(size=6, opacity=0.7))\n",
    "        fig.update_layout(\n",
    "            title={\n",
    "                \"text\": f\"<b>2D Visualization of Embeddings ({title_method}, Normalized)</b>\",\n",
    "                \"x\": 0.5,\n",
    "                \"xanchor\": \"center\",\n",
    "                \"font\": {\"size\": 18, \"family\": \"Arial, sans-serif\"},\n",
    "            },\n",
    "            font={\"family\": \"Arial, sans-serif\", \"size\": 12},\n",
    "            width=1200,\n",
    "            height=600,\n",
    "        )\n",
    "\n",
    "    else:  # separate\n",
    "        n_models = len(embeddings_list)\n",
    "        fig = make_subplots(\n",
    "            rows=1, cols=n_models, subplot_titles=model_names, horizontal_spacing=0.05\n",
    "        )\n",
    "\n",
    "        # Compute all reductions\n",
    "        all_reduced = []\n",
    "        all_explained_vars = []\n",
    "\n",
    "        for embeddings in embeddings_list:\n",
    "            if method.lower() == \"pca\":\n",
    "                reducer = PCA(n_components=2)\n",
    "                reduced = reducer.fit_transform(embeddings)\n",
    "                explained_var = reducer.explained_variance_ratio_.sum()\n",
    "                all_explained_vars.append(explained_var)\n",
    "            elif method.lower() == \"tsne\":\n",
    "                reducer = TSNE(n_components=2, random_state=42)\n",
    "                reduced = reducer.fit_transform(embeddings)\n",
    "                all_explained_vars.append(None)\n",
    "\n",
    "            all_reduced.append(reduced)\n",
    "\n",
    "        # Compute shared axis ranges if requested\n",
    "        if shared_axes:\n",
    "            all_x = np.concatenate([r[:, 0] for r in all_reduced])\n",
    "            all_y = np.concatenate([r[:, 1] for r in all_reduced])\n",
    "            x_min, x_max = all_x.min(), all_x.max()\n",
    "            y_min, y_max = all_y.min(), all_y.max()\n",
    "            x_padding = (x_max - x_min) * 0.05\n",
    "            y_padding = (y_max - y_min) * 0.05\n",
    "            x_range = [x_min - x_padding, x_max + x_padding]\n",
    "            y_range = [y_min - y_padding, y_max + y_padding]\n",
    "\n",
    "        # Create plots\n",
    "        for i, (reduced, model_name, explained_var) in enumerate(\n",
    "            zip(all_reduced, model_names, all_explained_vars)\n",
    "        ):\n",
    "            if explained_var is not None:\n",
    "                subtitle_suffix = f\"<br>(Explained var: {explained_var:.1%})\"\n",
    "            else:\n",
    "                subtitle_suffix = \"\"\n",
    "\n",
    "            # Truncate quotes to 50 characters for hover display\n",
    "            hover_text = [\n",
    "                f\"Quote: {q[:50]}...\" if len(q) > 50 else f\"Quote: {q}\"\n",
    "                for q in quotes\n",
    "            ]\n",
    "\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=reduced[:, 0],\n",
    "                    y=reduced[:, 1],\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(size=5, opacity=0.6),\n",
    "                    text=hover_text,\n",
    "                    hovertemplate=\"%{text}<br>x: %{x:.3f}<br>y: %{y:.3f}<extra></extra>\",\n",
    "                    showlegend=False,\n",
    "                ),\n",
    "                row=1,\n",
    "                col=i + 1,\n",
    "            )\n",
    "\n",
    "            fig.layout.annotations[i].update(\n",
    "                text=model_name + subtitle_suffix,\n",
    "                font=dict(family=\"Arial, sans-serif\", size=14),\n",
    "            )\n",
    "\n",
    "            if shared_axes:\n",
    "                fig.update_xaxes(range=x_range, row=1, col=i + 1)\n",
    "                fig.update_yaxes(range=y_range, row=1, col=i + 1)\n",
    "\n",
    "        method_name = \"PCA\" if method.lower() == \"pca\" else \"t-SNE\"\n",
    "        axes_note = \" (Shared Axes)\" if shared_axes else \" (Independent Axes)\"\n",
    "\n",
    "        fig.update_layout(\n",
    "            title={\n",
    "                \"text\": f\"<b>Separate {method_name} per Model{axes_note}</b>\",\n",
    "                \"x\": 0.5,\n",
    "                \"xanchor\": \"center\",\n",
    "                \"font\": {\"size\": 18, \"family\": \"Arial, sans-serif\"},\n",
    "            },\n",
    "            font={\"family\": \"Arial, sans-serif\", \"size\": 12},\n",
    "            width=1200,\n",
    "            height=425,\n",
    "            showlegend=False,\n",
    "        )\n",
    "\n",
    "    # Save as PNG with high resolution (scale=3 means 3x the size)\n",
    "    output_path = f\"visualizations/{filename}.png\"\n",
    "    os.makedirs(\"visualizations\", exist_ok=True)\n",
    "    fig.write_image(output_path, scale=3)\n",
    "    print(f\"Saved: {output_path}\")\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0yib0kwievi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all three visualizations as high-resolution PNGs\n",
    "print(\"Saving visualizations to the 'visualizations' folder...\\n\")\n",
    "\n",
    "# 1. Combined PCA with normalization\n",
    "print(\"1. Combined PCA (Normalized)...\")\n",
    "save_visualization_as_png(\n",
    "    [embeddings_google, embeddings_qwen, embeddings_ibm, embeddings_tencent],\n",
    "    [\"Google EmbeddingGemma\", \"Qwen3 Embedding\", \"IBM Granite\", \"Tencent Conan\"],\n",
    "    quotes,\n",
    "    method=\"pca\",\n",
    "    filename=\"combined_pca_normalized\",\n",
    "    viz_type=\"combined\",\n",
    ")\n",
    "\n",
    "# 2. Separate PCA per model (with shared axes)\n",
    "print(\"\\n2. Separate PCA per Model (Shared Axes)...\")\n",
    "save_visualization_as_png(\n",
    "    [embeddings_google, embeddings_qwen, embeddings_ibm, embeddings_tencent],\n",
    "    [\"Google EmbeddingGemma\", \"Qwen3 Embedding\", \"IBM Granite\", \"Tencent Conan\"],\n",
    "    quotes,\n",
    "    method=\"pca\",\n",
    "    filename=\"separate_pca_shared_axes\",\n",
    "    viz_type=\"separate\",\n",
    "    shared_axes=False,\n",
    ")\n",
    "\n",
    "# 3. Combined t-SNE with normalization\n",
    "print(\"\\n3. Combined t-SNE (Normalized)...\")\n",
    "save_visualization_as_png(\n",
    "    [embeddings_google, embeddings_qwen, embeddings_ibm, embeddings_tencent],\n",
    "    [\"Google EmbeddingGemma\", \"Qwen3 Embedding\", \"IBM Granite\", \"Tencent Conan\"],\n",
    "    quotes,\n",
    "    method=\"tsne\",\n",
    "    filename=\"combined_tsne_normalized\",\n",
    "    viz_type=\"combined\",\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"All visualizations saved successfully!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nOutput files:\")\n",
    "print(\"  - visualizations/combined_pca_normalized.png\")\n",
    "print(\"  - visualizations/separate_pca_shared_axes.png\")\n",
    "print(\"  - visualizations/combined_tsne_normalized.png\")\n",
    "print(\"\\nAll images are saved at 3x resolution for high quality.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jz6xgb2igur",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the animated visualization as an interactive HTML file and animated GIF\n",
    "print(\"Saving animated visualization...\\n\")\n",
    "\n",
    "# Save as HTML\n",
    "html_path = \"visualizations/combined_tsne_normalized_animated.html\"\n",
    "os.makedirs(\"visualizations\", exist_ok=True)\n",
    "animated_fig.write_html(html_path)\n",
    "print(f\"HTML saved: {html_path}\")\n",
    "\n",
    "# Save as animated GIF\n",
    "# Note: This requires kaleido and PIL/Pillow packages\n",
    "print(\"\\nGenerating animated GIF (this may take a moment)...\")\n",
    "\n",
    "try:\n",
    "    from PIL import Image\n",
    "    import io\n",
    "    \n",
    "    # Create a clean layout for GIF (without controls but WITH annotations)\n",
    "    gif_layout = go.Layout(\n",
    "        title={\n",
    "            \"text\": animated_fig.layout.title.text,\n",
    "            \"x\": 0.5,\n",
    "            \"xanchor\": \"center\",\n",
    "            \"font\": {\"size\": 18, \"family\": \"Arial, sans-serif\"},\n",
    "        },\n",
    "        xaxis={\"title\": animated_fig.layout.xaxis.title.text, \"range\": animated_fig.layout.xaxis.range},\n",
    "        yaxis={\"title\": animated_fig.layout.yaxis.title.text, \"range\": animated_fig.layout.yaxis.range},\n",
    "        font={\"family\": \"Arial, sans-serif\", \"size\": 12},\n",
    "        width=1200,\n",
    "        height=600,\n",
    "        showlegend=True,\n",
    "        annotations=list(animated_fig.layout.annotations) if animated_fig.layout.annotations else [],\n",
    "        # No updatemenus or sliders for clean GIF\n",
    "    )\n",
    "    \n",
    "    # Extract frames from the Plotly figure\n",
    "    gif_frames = []\n",
    "    num_frames = len(animated_fig.frames)\n",
    "    \n",
    "    print(f\"Processing {num_frames} frames...\")\n",
    "    \n",
    "    # Create each frame as an image\n",
    "    for i in range(num_frames):\n",
    "        # Create a figure with the clean layout (no controls but with annotations)\n",
    "        frame_fig = go.Figure(\n",
    "            data=animated_fig.frames[i].data,\n",
    "            layout=gif_layout\n",
    "        )\n",
    "        \n",
    "        # Convert to image bytes\n",
    "        img_bytes = frame_fig.to_image(format=\"png\", width=1200, height=600, scale=2)\n",
    "        img = Image.open(io.BytesIO(img_bytes))\n",
    "        gif_frames.append(img)\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"  Processed {i + 1}/{num_frames} frames...\")\n",
    "    \n",
    "    # Save as animated GIF\n",
    "    # Omit the loop parameter to play once without repeating\n",
    "    # (loop=0 means infinite, loop=1 means play twice)\n",
    "    gif_path = \"visualizations/combined_tsne_normalized_animated.gif\"\n",
    "    gif_frames[0].save(\n",
    "        gif_path,\n",
    "        save_all=True,\n",
    "        append_images=gif_frames[1:],\n",
    "        duration=33,  # 33ms per frame = ~30 FPS\n",
    "        optimize=False  # Set to True to reduce file size (but slower)\n",
    "        # No loop parameter = play once (behavior may vary by viewer)\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nGIF saved: {gif_path}\")\n",
    "    print(f\"  - Frames: {num_frames}\")\n",
    "    print(f\"  - Frame rate: ~30 FPS (33ms per frame)\")\n",
    "    print(f\"  - Looping: No loop parameter (plays once in most viewers)\")\n",
    "    print(f\"  - Controls: Hidden (clean animation)\")\n",
    "    print(f\"  - Annotations: Included in all frames\")\n",
    "    \n",
    "    # Get file size\n",
    "    import os\n",
    "    file_size = os.path.getsize(gif_path) / (1024 * 1024)  # Convert to MB\n",
    "    print(f\"  - File size: {file_size:.2f} MB\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"Error: Missing required packages for GIF export.\")\n",
    "    print(f\"Please install: pip install pillow kaleido\")\n",
    "    print(f\"Details: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating GIF: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Visualization files created:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  - HTML: {html_path}\")\n",
    "print(f\"    (Interactive, with play/pause controls)\")\n",
    "if 'gif_path' in locals():\n",
    "    print(f\"  - GIF: {gif_path}\")\n",
    "    print(f\"    (Clean animation with annotation, plays once)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b568a7",
   "metadata": {},
   "source": [
    "## Multi-Dimension Embedding Generation\n",
    "\n",
    "The `generate_embeddings_multi_dimension()` function allows you to generate embeddings at multiple dimensions (128, 256, 512, 768) in a single call. This is useful for comparing how different dimension sizes affect the embedding space and model performance.\n",
    "\n",
    "**Features:**\n",
    "- Generates embeddings at multiple specified dimensions\n",
    "- Saves all embeddings to a dedicated `dimension_tests/` folder\n",
    "- Returns a dictionary mapping dimensions to file paths\n",
    "- Provides progress feedback during generation\n",
    "\n",
    "**Note:** The default dimensions are [128, 256, 512, 768] to match the model's maximum supported dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9wa4l845fve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dimensions_separately(\n",
    "    embeddings_dict: dict[int, ndarray],\n",
    "    model_name: str,\n",
    "    quotes: list[str] = None,\n",
    "    method: str = \"pca\",\n",
    "    shared_axes: bool = True,\n",
    "):\n",
    "    \"\"\"Visualize embeddings at different dimensions with separate dimensionality reduction per dimension.\n",
    "\n",
    "    This approach applies PCA/t-SNE independently to each dimension's embeddings,\n",
    "    showing how the embedding space structure varies across dimensions.\n",
    "    Dimensions are displayed side-by-side in subplots for comparison.\n",
    "\n",
    "    Args:\n",
    "        embeddings_dict (dict[int, ndarray]): Dictionary mapping dimension sizes to embeddings arrays.\n",
    "        model_name (str): The name of the model (for the title).\n",
    "        quotes (list[str], optional): Original quote texts for hover display.\n",
    "        method (str): Dimensionality reduction method - \"pca\" or \"tsne\"\n",
    "        shared_axes (bool): If True, all subplots use the same x/y axis ranges for direct comparison\n",
    "    \"\"\"\n",
    "    # Sort dimensions for consistent ordering\n",
    "    dimensions = sorted(embeddings_dict.keys())\n",
    "    n_dims = len(dimensions)\n",
    "    \n",
    "    # Create subplot titles with dimension info\n",
    "    subplot_titles = [f\"{dim} Dimensions\" for dim in dimensions]\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=n_dims, subplot_titles=subplot_titles, horizontal_spacing=0.05\n",
    "    )\n",
    "\n",
    "    # First pass: compute all reductions and find global ranges if needed\n",
    "    all_reduced = []\n",
    "    all_explained_vars = []\n",
    "\n",
    "    for dim in dimensions:\n",
    "        embeddings = embeddings_dict[dim]\n",
    "        \n",
    "        # Apply dimensionality reduction independently\n",
    "        if method.lower() == \"pca\":\n",
    "            reducer = PCA(n_components=2)\n",
    "            reduced = reducer.fit_transform(embeddings)\n",
    "            explained_var = reducer.explained_variance_ratio_.sum()\n",
    "            all_explained_vars.append(explained_var)\n",
    "        elif method.lower() == \"tsne\":\n",
    "            reducer = TSNE(n_components=2, random_state=42)\n",
    "            reduced = reducer.fit_transform(embeddings)\n",
    "            all_explained_vars.append(None)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "        all_reduced.append(reduced)\n",
    "\n",
    "    # Compute shared axis ranges if requested\n",
    "    if shared_axes:\n",
    "        all_x = np.concatenate([r[:, 0] for r in all_reduced])\n",
    "        all_y = np.concatenate([r[:, 1] for r in all_reduced])\n",
    "        x_min, x_max = all_x.min(), all_x.max()\n",
    "        y_min, y_max = all_y.min(), all_y.max()\n",
    "        # Add small padding (5%)\n",
    "        x_padding = (x_max - x_min) * 0.05\n",
    "        y_padding = (y_max - y_min) * 0.05\n",
    "        x_range = [x_min - x_padding, x_max + x_padding]\n",
    "        y_range = [y_min - y_padding, y_max + y_padding]\n",
    "\n",
    "    # Second pass: create plots\n",
    "    for i, (dim, reduced, explained_var) in enumerate(\n",
    "        zip(dimensions, all_reduced, all_explained_vars)\n",
    "    ):\n",
    "        # Prepare subtitle with explained variance\n",
    "        if explained_var is not None:\n",
    "            subtitle_suffix = f\"<br>(Explained var: {explained_var:.1%})\"\n",
    "        else:\n",
    "            subtitle_suffix = \"\"\n",
    "\n",
    "        # Prepare hover text with truncated quotes\n",
    "        if quotes is not None:\n",
    "            hover_text = [\n",
    "                f\"Quote: {q[:50]}...\" if len(q) > 50 else f\"Quote: {q}\"\n",
    "                for q in quotes\n",
    "            ]\n",
    "        else:\n",
    "            hover_text = None\n",
    "\n",
    "        # Add scatter trace\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=reduced[:, 0],\n",
    "                y=reduced[:, 1],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=5, opacity=0.6, color=px.colors.qualitative.Vivid[i % len(px.colors.qualitative.Vivid)]),\n",
    "                text=hover_text,\n",
    "                hovertemplate=\"%{text}<br>x: %{x:.3f}<br>y: %{y:.3f}<extra></extra>\",\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=1,\n",
    "            col=i + 1,\n",
    "        )\n",
    "\n",
    "        # Update subplot title with explained variance and font\n",
    "        fig.layout.annotations[i].update(\n",
    "            text=f\"{dim} Dimensions{subtitle_suffix}\",\n",
    "            font=dict(family=\"Arial, sans-serif\", size=14),\n",
    "        )\n",
    "\n",
    "        # Set axis ranges\n",
    "        if shared_axes:\n",
    "            fig.update_xaxes(range=x_range, row=1, col=i + 1)\n",
    "            fig.update_yaxes(range=y_range, row=1, col=i + 1)\n",
    "\n",
    "    method_name = \"PCA\" if method.lower() == \"pca\" else \"t-SNE\"\n",
    "    axes_note = \" (Shared Axes)\" if shared_axes else \" (Independent Axes)\"\n",
    "\n",
    "    # Make title bold and centered, set Arial font, and increase resolution\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            \"text\": f\"<b>{model_name}: Separate {method_name} per Dimension{axes_note}</b>\",\n",
    "            \"x\": 0.5,\n",
    "            \"xanchor\": \"center\",\n",
    "            \"font\": {\"size\": 18, \"family\": \"Arial, sans-serif\"},\n",
    "        },\n",
    "        font={\"family\": \"Arial, sans-serif\", \"size\": 12},\n",
    "        width=1600,\n",
    "        height=400,\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    # Show with high resolution\n",
    "    fig.show(config={\"toImageButtonOptions\": {\"format\": \"png\", \"scale\": 3}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74heblr9x0h",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dimension_visualization_as_png(\n",
    "    embeddings_dict: dict[int, ndarray],\n",
    "    model_name: str,\n",
    "    quotes: list[str],\n",
    "    method: str,\n",
    "    filename: str,\n",
    "    shared_axes: bool = True,\n",
    "):\n",
    "    \"\"\"Save a dimension comparison visualization as a high-resolution PNG file.\n",
    "\n",
    "    Args:\n",
    "        embeddings_dict (dict[int, ndarray]): Dictionary mapping dimension sizes to embeddings arrays.\n",
    "        model_name (str): The name of the model (for the title).\n",
    "        quotes (list[str]): Original quote texts.\n",
    "        method (str): Dimensionality reduction method - \"pca\" or \"tsne\"\n",
    "        filename (str): Output filename (without extension)\n",
    "        shared_axes (bool): If True, all subplots use the same x/y axis ranges\n",
    "    \"\"\"\n",
    "    # Sort dimensions for consistent ordering\n",
    "    dimensions = sorted(embeddings_dict.keys())\n",
    "    n_dims = len(dimensions)\n",
    "    \n",
    "    # Create subplot titles\n",
    "    subplot_titles = [f\"{dim} Dimensions\" for dim in dimensions]\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=n_dims, subplot_titles=subplot_titles, horizontal_spacing=0.05\n",
    "    )\n",
    "\n",
    "    # First pass: compute all reductions and find global ranges if needed\n",
    "    all_reduced = []\n",
    "    all_explained_vars = []\n",
    "\n",
    "    for dim in dimensions:\n",
    "        embeddings = embeddings_dict[dim]\n",
    "        \n",
    "        if method.lower() == \"pca\":\n",
    "            reducer = PCA(n_components=2)\n",
    "            reduced = reducer.fit_transform(embeddings)\n",
    "            explained_var = reducer.explained_variance_ratio_.sum()\n",
    "            all_explained_vars.append(explained_var)\n",
    "        elif method.lower() == \"tsne\":\n",
    "            reducer = TSNE(n_components=2, random_state=42)\n",
    "            reduced = reducer.fit_transform(embeddings)\n",
    "            all_explained_vars.append(None)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "        all_reduced.append(reduced)\n",
    "\n",
    "    # Compute shared axis ranges if requested\n",
    "    if shared_axes:\n",
    "        all_x = np.concatenate([r[:, 0] for r in all_reduced])\n",
    "        all_y = np.concatenate([r[:, 1] for r in all_reduced])\n",
    "        x_min, x_max = all_x.min(), all_x.max()\n",
    "        y_min, y_max = all_y.min(), all_y.max()\n",
    "        x_padding = (x_max - x_min) * 0.05\n",
    "        y_padding = (y_max - y_min) * 0.05\n",
    "        x_range = [x_min - x_padding, x_max + x_padding]\n",
    "        y_range = [y_min - y_padding, y_max + y_padding]\n",
    "\n",
    "    # Second pass: create plots\n",
    "    for i, (dim, reduced, explained_var) in enumerate(\n",
    "        zip(dimensions, all_reduced, all_explained_vars)\n",
    "    ):\n",
    "        if explained_var is not None:\n",
    "            subtitle_suffix = f\"<br>(Explained var: {explained_var:.1%})\"\n",
    "        else:\n",
    "            subtitle_suffix = \"\"\n",
    "\n",
    "        hover_text = [\n",
    "            f\"Quote: {q[:50]}...\" if len(q) > 50 else f\"Quote: {q}\"\n",
    "            for q in quotes\n",
    "        ]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=reduced[:, 0],\n",
    "                y=reduced[:, 1],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=5, opacity=0.6, color=px.colors.qualitative.Vivid[i % len(px.colors.qualitative.Vivid)]),\n",
    "                text=hover_text,\n",
    "                hovertemplate=\"%{text}<br>x: %{x:.3f}<br>y: %{y:.3f}<extra></extra>\",\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=1,\n",
    "            col=i + 1,\n",
    "        )\n",
    "\n",
    "        fig.layout.annotations[i].update(\n",
    "            text=f\"{dim} Dimensions{subtitle_suffix}\",\n",
    "            font=dict(family=\"Arial, sans-serif\", size=14),\n",
    "        )\n",
    "\n",
    "        if shared_axes:\n",
    "            fig.update_xaxes(range=x_range, row=1, col=i + 1)\n",
    "            fig.update_yaxes(range=y_range, row=1, col=i + 1)\n",
    "\n",
    "    method_name = \"PCA\" if method.lower() == \"pca\" else \"t-SNE\"\n",
    "    axes_note = \" (Shared Axes)\" if shared_axes else \" (Independent Axes)\"\n",
    "\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            \"text\": f\"<b>{model_name}: Separate {method_name} per Dimension{axes_note}</b>\",\n",
    "            \"x\": 0.5,\n",
    "            \"xanchor\": \"center\",\n",
    "            \"font\": {\"size\": 18, \"family\": \"Arial, sans-serif\"},\n",
    "        },\n",
    "        font={\"family\": \"Arial, sans-serif\", \"size\": 12},\n",
    "        width=1600,\n",
    "        height=500,\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    # Save as PNG with high resolution\n",
    "    output_path = f\"visualizations/{filename}.png\"\n",
    "    os.makedirs(\"visualizations\", exist_ok=True)\n",
    "    fig.write_image(output_path, scale=3)\n",
    "    print(f\"Saved: {output_path}\")\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j5pkaykl3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Generate embeddings at multiple dimensions for Google EmbeddingGemma model\n",
    "\n",
    "dimension_results = generate_embeddings_multi_dimension(\n",
    "    model=google_model,\n",
    "    model_name=\"google-embedding-gemma-300m\",\n",
    "    quotes=quotes,\n",
    "    dimensions=[128, 256, 512, 768]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Generated files:\")\n",
    "for dim, path in dimension_results.items():\n",
    "    print(f\"  {dim} Dimensions: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5495fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load and verify embeddings from dimension_tests folder\n",
    "\n",
    "print(\"Loading embeddings from dimension_tests folder...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "dimensions_to_check = [128, 256, 512, 768]\n",
    "model_name = \"google-embedding-gemma-300m\"\n",
    "\n",
    "for dim in dimensions_to_check:\n",
    "    file_path = f\"dimension_tests/{model_name}-{dim}.npy\"\n",
    "    embeddings = load_embeddings(file_path)\n",
    "    print(f\"\\nDimension {dim}:\")\n",
    "    print(f\"  Shape: {embeddings.shape}\")\n",
    "    print(f\"  Expected: (200, {dim})\")\n",
    "    print(f\"  Match: {embeddings.shape == (200, dim)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dpocr7f5f3k",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Visualize embeddings at different dimensions side-by-side\n",
    "\n",
    "# Load embeddings for all dimensions\n",
    "embeddings_128 = load_embeddings(\"dimension_tests/google-embedding-gemma-300m-128.npy\")\n",
    "embeddings_256 = load_embeddings(\"dimension_tests/google-embedding-gemma-300m-256.npy\")\n",
    "embeddings_512 = load_embeddings(\"dimension_tests/google-embedding-gemma-300m-512.npy\")\n",
    "embeddings_768 = load_embeddings(\"dimension_tests/google-embedding-gemma-300m-768.npy\")\n",
    "\n",
    "# Create dictionary mapping dimensions to embeddings\n",
    "embeddings_by_dimension = {\n",
    "    128: embeddings_128,\n",
    "    256: embeddings_256,\n",
    "    512: embeddings_512,\n",
    "    768: embeddings_768,\n",
    "}\n",
    "\n",
    "# Visualize with PCA\n",
    "print(\"Visualizing different dimensions side-by-side using PCA...\")\n",
    "visualize_dimensions_separately(\n",
    "    embeddings_dict=embeddings_by_dimension,\n",
    "    model_name=\"Google EmbeddingGemma 300m\",\n",
    "    quotes=quotes,\n",
    "    method=\"pca\",\n",
    "    shared_axes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0qxou3zz5hyl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Visualize different dimensions using t-SNE (alternative method)\n",
    "\n",
    "print(\"Visualizing different dimensions side-by-side using t-SNE...\")\n",
    "print(\"Note: t-SNE may take longer to compute but preserves local structure better\\n\")\n",
    "\n",
    "visualize_dimensions_separately(\n",
    "    embeddings_dict=embeddings_by_dimension,\n",
    "    model_name=\"Google EmbeddingGemma 300m\",\n",
    "    quotes=quotes,\n",
    "    method=\"tsne\",\n",
    "    shared_axes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r7233d9ymum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dimension comparison visualizations as high-resolution PNGs\n",
    "print(\"Saving dimension comparison visualizations...\\n\")\n",
    "\n",
    "# 1. Save PCA dimension comparison\n",
    "print(\"1. Dimension Comparison - PCA (Shared Axes)...\")\n",
    "save_dimension_visualization_as_png(\n",
    "    embeddings_dict=embeddings_by_dimension,\n",
    "    model_name=\"Google EmbeddingGemma 300m\",\n",
    "    quotes=quotes,\n",
    "    method=\"pca\",\n",
    "    filename=\"dimension_comparison_pca_shared_axes\",\n",
    "    shared_axes=True,\n",
    ")\n",
    "\n",
    "# 2. Save t-SNE dimension comparison\n",
    "print(\"\\n2. Dimension Comparison - t-SNE (Shared Axes)...\")\n",
    "save_dimension_visualization_as_png(\n",
    "    embeddings_dict=embeddings_by_dimension,\n",
    "    model_name=\"Google EmbeddingGemma 300m\",\n",
    "    quotes=quotes,\n",
    "    method=\"tsne\",\n",
    "    filename=\"dimension_comparison_tsne_shared_axes\",\n",
    "    shared_axes=True,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Dimension comparison visualizations saved successfully!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nOutput files:\")\n",
    "print(\"  - visualizations/dimension_comparison_pca_shared_axes.png\")\n",
    "print(\"  - visualizations/dimension_comparison_tsne_shared_axes.png\")\n",
    "print(\"\\nAll images are saved at 3x resolution for high quality.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42bed03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
