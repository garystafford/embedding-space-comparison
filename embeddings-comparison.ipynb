{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd8700c",
   "metadata": {},
   "source": [
    "# Text Embedding Comparison\n",
    "\n",
    "The Notebook creates and visualizes 200 text embeddings at 512 dimensions each, projected into 2D for visualization, across four popular open weight text embedding models from Google, Qwen, IBM, and Tencent. Even with identical inputs and dimensionality, each model induces its own embedding space—with different clusters, separations, and neighborhood relationships—which is why production systems need explicit embedding‑model versioning and a full re‑embedding plus re‑indexing step whenever the underlying model changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a63948",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820055c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pip -Uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6786118",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt -Uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc8d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Disable tokenizers parallelism warnings in notebook contexts\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5597b604",
   "metadata": {},
   "source": [
    "## Authenticate with Hugging Face\n",
    "\n",
    "**IMPORTANT: Complete these steps in order:**\n",
    "\n",
    "1. **Request model access**: Visit https://huggingface.co/google/embeddinggemma-300m and click \"Request access to this model\" (requires a free Hugging Face account)\n",
    "2. **Wait for approval**: Access is usually granted immediately or within a few minutes\n",
    "3. **Get your token**: Go to https://huggingface.co/settings/tokens and create a new token (read permission is sufficient)\n",
    "4. **Run the login cell below**: Execute the next cell and paste your token in the text box that appears\n",
    "5. **Verify login**: Run the verification cell to confirm you're authenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae23e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# Login to Hugging Face (this will show a widget for entering your token)\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6efc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify authentication status\n",
    "from huggingface_hub import whoami\n",
    "\n",
    "try:\n",
    "    user_info = whoami()\n",
    "    print(f\"✓ Successfully logged in as: {user_info['name']}\")\n",
    "    print(f\"✓ Authentication token is valid\")\n",
    "except Exception as e:\n",
    "    print(\"✗ Not logged in or token is invalid\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07be16f4",
   "metadata": {},
   "source": [
    "## Load Quotes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb414735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def load_all_quotes(file_path):\n",
    "    quotes = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            quote = json.loads(line)\n",
    "            quotes.append(quote[\"inputs\"])\n",
    "    return quotes\n",
    "\n",
    "\n",
    "file_path = \"quotes/quotes_200.jsonl\"\n",
    "quotes = load_all_quotes(file_path)\n",
    "print(f\"Total number of quotes: {len(quotes)}\")\n",
    "print(f\"First quote in list: {quotes[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88428ca9",
   "metadata": {},
   "source": [
    "## Common Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada52d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def compute_similarity_test(model: SentenceTransformer) -> Tensor:\n",
    "    \"\"\"Compute the similarity between queries and answers using the given model.\n",
    "\n",
    "    Args:\n",
    "        model (SentenceTransformer): The sentence transformer model to use for encoding and similarity computation.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: A tensor containing the similarity scores between each query and answer.\n",
    "    \"\"\"\n",
    "    # The queries and quotes to embed\n",
    "    queries = [\n",
    "        \"What is the capital of China?\",\n",
    "        \"Explain gravity\",\n",
    "    ]\n",
    "    answers = [\n",
    "        \"The capital of China is Beijing.\",\n",
    "        \"Gravity is a force that attracts two bodies towards each other. It gives weight to physical objects and is responsible for the movement of planets around the sun.\",\n",
    "    ]\n",
    "\n",
    "    # Encode the queries and quotes. Note that queries benefit from using a prompt\n",
    "    # Here we use the prompt called \"query\" stored under `model.prompts`, but you can\n",
    "    # also pass your own prompt via the `prompt` argument\n",
    "    query_embeddings = model.encode_query(queries, prompt_name=\"query\")\n",
    "    quote_embeddings = model.encode_document(answers)\n",
    "\n",
    "    # Compute the (cosine) similarity between the query and quote embeddings\n",
    "    similarity = model.similarity(query_embeddings, quote_embeddings)\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7de7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ndarray\n",
    "\n",
    "\n",
    "def generate_embeddings(model: SentenceTransformer, quotes: list[str], dimensions: int=512) -> ndarray:\n",
    "    \"\"\"Embed a list of quotes using the given model and measure the time taken.\n",
    "\n",
    "    Args:\n",
    "        model (SentenceTransformer): The sentence transformer model to use for encoding.\n",
    "        quotes (list[str]): A list of quotes to embed.\n",
    "    \"\"\"\n",
    "    import time\n",
    "\n",
    "    start_time = time.time()\n",
    "    quote_embeddings = model.encode(\n",
    "        quotes,\n",
    "        batch_size=32,\n",
    "        show_progress_bar=True,\n",
    "        truncate_dim=dimensions,  # <- desired output dim\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Time taken: {end_time - start_time} seconds\")\n",
    "    print(f\"Time per embedding: {(end_time - start_time) / len(quotes)} seconds\")\n",
    "\n",
    "    return quote_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f9d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def save_embeddings(quote_embeddings: ndarray, file_name: str) -> str:\n",
    "    \"\"\"Save the quote embeddings to a file.\n",
    "\n",
    "    Args:\n",
    "        quote_embeddings (ndarray): The quote embeddings to save.\n",
    "        file_name (str): The name of the file to save the embeddings to.\n",
    "\n",
    "    Returns:\n",
    "        str: The path to the saved embeddings file.\n",
    "    \"\"\"\n",
    "    embeddings_path = os.path.join(\"embeddings\", file_name)\n",
    "    np.save(embeddings_path, quote_embeddings)\n",
    "\n",
    "    return embeddings_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f818f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(embeddings_path: str) -> ndarray:\n",
    "    \"\"\"Load embeddings from a file.\n",
    "\n",
    "    Args:\n",
    "        embeddings_path (str): Path to the file containing the saved embeddings.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: The loaded embeddings as a NumPy array.\n",
    "    \"\"\"\n",
    "    embeddings = np.load(embeddings_path)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8988bdc",
   "metadata": {},
   "source": [
    "## Model 1: EmbeddingGemma\n",
    "\n",
    "`google/embeddinggemma-300m`\n",
    "\n",
    "https://huggingface.co/google/embeddinggemma-300m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516d90f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "google_model = SentenceTransformer(\"google/embeddinggemma-300m\")\n",
    "print(f\"Model loaded: {google_model.model_card_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95282b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test inference with queries and answers\n",
    "similarities = compute_similarity_test(google_model)\n",
    "print(f\"Similarities: {similarities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b63ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the quotes\n",
    "embeddings = generate_embeddings(google_model, quotes, 512)\n",
    "print(f\"Shape: {embeddings.shape}\")  # (200, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbd94e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the quote embeddings to a file for later use\n",
    "embeddings_path = save_embeddings(embeddings, \"google-embedding-gemma-300m-512.npy\")\n",
    "print(f\"Embeddings saved to: {embeddings_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16083a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the quote embeddings from the file\n",
    "loaded_embeddings = load_embeddings(embeddings_path)\n",
    "print(f\"Shape: {loaded_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ac7a1",
   "metadata": {},
   "source": [
    "## Model 2: Qwen3 Embedding 0.6B\n",
    "\n",
    "`Qwen/Qwen3-Embedding-0.6B`\n",
    "\n",
    "https://huggingface.co/Qwen/Qwen3-Embedding-0.6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f927fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "qwen_model = SentenceTransformer(\"Qwen/Qwen3-Embedding-0.6B\")\n",
    "print(f\"Model loaded: {qwen_model.model_card_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38619d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test inference with queries and answers\n",
    "similarities = compute_similarity_test(qwen_model)\n",
    "print(f\"Similarities: {similarities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af91186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the quotes\n",
    "embeddings = generate_embeddings(qwen_model, quotes, 512)\n",
    "print(f\"Shape: {embeddings.shape}\")  # (200, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538b72a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the quote embeddings to a file for later use\n",
    "embeddings_path = save_embeddings(embeddings, \"qwen-qwen3-embedding-0.6b-512.npy\")\n",
    "print(f\"Embeddings saved to: {embeddings_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7ea664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the quote embeddings from the file\n",
    "loaded_embeddings = load_embeddings(embeddings_path)\n",
    "print(f\"Shape: {loaded_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42079f81",
   "metadata": {},
   "source": [
    "## Model 3: IBM Granite Embedding 125m English\n",
    "\n",
    "`ibm-granite/granite-embedding-125m-english`\n",
    "\n",
    "https://huggingface.co/ibm-granite/granite-embedding-125m-english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4000064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "ibm_model = SentenceTransformer(\"ibm-granite/granite-embedding-125m-english\")\n",
    "print(f\"Model loaded: {ibm_model.model_card_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d6b826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test inference with queries and answers\n",
    "similarities = compute_similarity_test(ibm_model)\n",
    "print(f\"Similarities: {similarities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f68b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the quotes\n",
    "embeddings = generate_embeddings(ibm_model, quotes, 512)\n",
    "print(f\"Shape: {embeddings.shape}\")  # (200, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0815ce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the quote embeddings to a file for later use\n",
    "embeddings_path = save_embeddings(\n",
    "    embeddings, \"ibm-granite-embedding-125m-english-512.npy\"\n",
    ")\n",
    "print(f\"Embeddings saved to: {embeddings_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba4f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the quote embeddings from the file\n",
    "loaded_embeddings = load_embeddings(embeddings_path)\n",
    "print(f\"Shape: {loaded_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bbf694",
   "metadata": {},
   "source": [
    "## Model 4: TencentBAC Conan Embedding v1\n",
    "\n",
    "`TencentBAC/Conan-embedding-v1`\n",
    "\n",
    "https://huggingface.co/TencentBAC/Conan-embedding-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69b748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "tencent_model = SentenceTransformer(\"TencentBAC/Conan-embedding-v1\")\n",
    "print(f\"Model loaded: {tencent_model.model_card_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test inference with queries and answers\n",
    "similarities = compute_similarity_test(tencent_model)\n",
    "print(f\"Similarities: {similarities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a839dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the quotes\n",
    "embeddings = generate_embeddings(tencent_model, quotes, 512)\n",
    "print(f\"Shape: {embeddings.shape}\")  # (200, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a60cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the quote embeddings to a file for later use\n",
    "embeddings_path = save_embeddings(embeddings, \"tencentbac-conan-embedding-v1-512.npy\")\n",
    "print(f\"Embeddings saved to: {embeddings_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8880fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the quote embeddings from the file\n",
    "loaded_embeddings = load_embeddings(embeddings_path)\n",
    "print(f\"Shape: {loaded_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7sba3ipzzbk",
   "metadata": {},
   "source": [
    "## Visualization Methods\n",
    "\n",
    "**`normalize_embeddings()`**\n",
    "- L2 normalizes embeddings to unit length\n",
    "- Standardizes to zero mean and unit variance\n",
    "- Ensures all models are on comparable scales\n",
    "\n",
    "**`visualize_multiple_embeddings_improved()`**\n",
    "- Normalizes each model's embeddings separately before combining\n",
    "- Reports PCA explained variance ratio\n",
    "- Supports both PCA and t-SNE\n",
    "- Includes hover text with quote content\n",
    "- Better for direct comparison when normalization is appropriate\n",
    "\n",
    "**`visualize_embeddings_separately()`**\n",
    "- Applies PCA/t-SNE independently to each model\n",
    "- Shows true structure of each embedding space\n",
    "- No cross-contamination between models\n",
    "- Side-by-side subplots for comparison\n",
    "- Better for understanding individual model characteristics\n",
    "\n",
    "### When to Use Which:\n",
    "- **Separate visualization** (`visualize_embeddings_separately`): Best for understanding each model's embedding space structure independently\n",
    "- **Combined normalized** (`visualize_multiple_embeddings_improved`): Best for direct comparison when you want to see relative positions across models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13415129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xnicusv9aar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_embeddings(embeddings: ndarray) -> ndarray:\n",
    "    \"\"\"Normalize embeddings using L2 normalization followed by standardization.\n",
    "\n",
    "    This ensures embeddings from different models are on comparable scales:\n",
    "    1. L2 normalization: Scale each embedding vector to unit length\n",
    "    2. Standardization: Zero mean and unit variance per dimension\n",
    "\n",
    "    Args:\n",
    "        embeddings (ndarray): The embeddings to normalize (shape: [n_samples, n_dimensions])\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Normalized embeddings with the same shape\n",
    "    \"\"\"\n",
    "    # Step 1: L2 normalize each embedding vector to unit length\n",
    "    # This makes all vectors lie on a hypersphere\n",
    "    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    # Avoid division by zero\n",
    "    norms = np.where(norms == 0, 1, norms)\n",
    "    l2_normalized = embeddings / norms\n",
    "\n",
    "    # Step 2: Standardize to zero mean and unit variance per dimension\n",
    "    # This ensures different models have comparable variance structures\n",
    "    mean = l2_normalized.mean(axis=0)\n",
    "    std = l2_normalized.std(axis=0)\n",
    "    # Avoid division by zero for constant dimensions\n",
    "    std = np.where(std == 0, 1, std)\n",
    "    standardized = (l2_normalized - mean) / std\n",
    "\n",
    "    return standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7xbx8w7kac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_multiple_embeddings_improved(\n",
    "    embeddings_list: list[ndarray],\n",
    "    model_names: list[str],\n",
    "    quotes: list[str] = None,\n",
    "    method: str = \"pca\",\n",
    "):\n",
    "    \"\"\"Visualize multiple sets of embeddings in 2D space with proper normalization.\n",
    "\n",
    "    This function addresses methodological issues by:\n",
    "    1. Normalizing each model's embeddings separately before combining\n",
    "    2. Reporting explained variance for PCA\n",
    "    3. Supporting both PCA and t-SNE\n",
    "    4. Adding hover text with quote content\n",
    "\n",
    "    Args:\n",
    "        embeddings_list (list[ndarray]): A list of embeddings to visualize.\n",
    "        model_names (list[str]): A list of model names corresponding to the embeddings.\n",
    "        quotes (list[str], optional): Original quote texts for hover display.\n",
    "        method (str): Dimensionality reduction method - \"pca\" or \"tsne\"\n",
    "    \"\"\"\n",
    "    print(\"Normalizing embeddings for each model separately...\")\n",
    "    normalized_embeddings = []\n",
    "    for i, emb in enumerate(embeddings_list):\n",
    "        norm_emb = normalize_embeddings(emb)\n",
    "        normalized_embeddings.append(norm_emb)\n",
    "        print(f\"  {model_names[i]}: normalized {emb.shape[0]} embeddings\")\n",
    "\n",
    "    # Combine normalized embeddings\n",
    "    combined_embeddings = np.vstack(normalized_embeddings)\n",
    "    print(f\"\\nCombined shape: {combined_embeddings.shape}\")\n",
    "\n",
    "    # Apply dimensionality reduction\n",
    "    if method.lower() == \"pca\":\n",
    "        reducer = PCA(n_components=2)\n",
    "        reduced_embeddings = reducer.fit_transform(combined_embeddings)\n",
    "\n",
    "        # Report explained variance - critical for understanding information loss\n",
    "        print(f\"\\nPCA Explained Variance:\")\n",
    "        print(f\"  PC1: {reducer.explained_variance_ratio_[0]:.2%}\")\n",
    "        print(f\"  PC2: {reducer.explained_variance_ratio_[1]:.2%}\")\n",
    "        print(f\"  Total: {reducer.explained_variance_ratio_.sum():.2%}\")\n",
    "\n",
    "        axis_labels = {\"x\": \"Principal Component 1\", \"y\": \"Principal Component 2\"}\n",
    "        title_method = \"PCA\"\n",
    "    elif method.lower() == \"tsne\":\n",
    "\n",
    "        print(\"\\nApplying t-SNE (this may take a moment)...\")\n",
    "        reducer = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "        reduced_embeddings = reducer.fit_transform(combined_embeddings)\n",
    "        axis_labels = {\"x\": \"t-SNE Dimension 1\", \"y\": \"t-SNE Dimension 2\"}\n",
    "        title_method = \"t-SNE\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}. Use 'pca' or 'tsne'\")\n",
    "\n",
    "    # Create a DataFrame for Plotly\n",
    "    df = pd.DataFrame(reduced_embeddings, columns=[\"dim1\", \"dim2\"])\n",
    "    df[\"Model\"] = np.repeat(model_names, [emb.shape[0] for emb in embeddings_list])\n",
    "\n",
    "    # Add quote text for hover if provided\n",
    "    if quotes is not None:\n",
    "        # Repeat quotes for each model\n",
    "        all_quotes = quotes * len(embeddings_list)\n",
    "        df[\"Quote\"] = all_quotes\n",
    "        hover_data = {\"Quote\": True, \"Model\": True, \"dim1\": \":.3f\", \"dim2\": \":.3f\"}\n",
    "    else:\n",
    "        hover_data = {\"Model\": True, \"dim1\": \":.3f\", \"dim2\": \":.3f\"}\n",
    "\n",
    "    # Create scatter plot\n",
    "    fig = px.scatter(\n",
    "        df,\n",
    "        x=\"dim1\",\n",
    "        y=\"dim2\",\n",
    "        color=\"Model\",\n",
    "        color_discrete_sequence=px.colors.qualitative.Set2,\n",
    "        title=f\"2D Visualization of Embeddings ({title_method}, Normalized)\",\n",
    "        labels={\"dim1\": axis_labels[\"x\"], \"dim2\": axis_labels[\"y\"]},\n",
    "        hover_data=hover_data,\n",
    "    )\n",
    "\n",
    "    fig.update_traces(marker=dict(size=6, opacity=0.7))\n",
    "\n",
    "    # Make title bold and centered, set Arial font, and increase resolution\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            \"text\": f\"<b>2D Visualization of Embeddings ({title_method}, Normalized)</b>\",\n",
    "            \"x\": 0.5,\n",
    "            \"xanchor\": \"center\",\n",
    "            \"font\": {\"size\": 18, \"family\": \"Arial, sans-serif\"},\n",
    "        },\n",
    "        font={\"family\": \"Arial, sans-serif\", \"size\": 12},\n",
    "        width=1200,\n",
    "        height=600,\n",
    "    )\n",
    "\n",
    "    # Show with high resolution\n",
    "    fig.show(config={\"toImageButtonOptions\": {\"format\": \"png\", \"scale\": 3}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ag440vewgla",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings_separately(\n",
    "    embeddings_list: list[ndarray],\n",
    "    model_names: list[str],\n",
    "    quotes: list[str] = None,\n",
    "    method: str = \"pca\",\n",
    "    shared_axes: bool = True,\n",
    "):\n",
    "    \"\"\"Visualize embeddings with separate dimensionality reduction per model.\n",
    "\n",
    "    This approach applies PCA/t-SNE independently to each model's embeddings,\n",
    "    showing the true structure of each embedding space without cross-contamination.\n",
    "    Models are displayed side-by-side in subplots for comparison.\n",
    "\n",
    "    Args:\n",
    "        embeddings_list (list[ndarray]): A list of embeddings to visualize.\n",
    "        model_names (list[str]): A list of model names corresponding to the embeddings.\n",
    "        quotes (list[str], optional): Original quote texts for hover display.\n",
    "        method (str): Dimensionality reduction method - \"pca\" or \"tsne\"\n",
    "        shared_axes (bool): If True, all subplots use the same x/y axis ranges for direct comparison\n",
    "    \"\"\"\n",
    "    n_models = len(embeddings_list)\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=n_models, subplot_titles=model_names, horizontal_spacing=0.1\n",
    "    )\n",
    "\n",
    "    # First pass: compute all reductions and find global ranges if needed\n",
    "    all_reduced = []\n",
    "    all_explained_vars = []\n",
    "\n",
    "    for embeddings in embeddings_list:\n",
    "        # Apply dimensionality reduction independently\n",
    "        if method.lower() == \"pca\":\n",
    "            reducer = PCA(n_components=2)\n",
    "            reduced = reducer.fit_transform(embeddings)\n",
    "            explained_var = reducer.explained_variance_ratio_.sum()\n",
    "            all_explained_vars.append(explained_var)\n",
    "        elif method.lower() == \"tsne\":\n",
    "            reducer = TSNE(n_components=2, random_state=42)\n",
    "            reduced = reducer.fit_transform(embeddings)\n",
    "            all_explained_vars.append(None)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "        all_reduced.append(reduced)\n",
    "\n",
    "    # Compute shared axis ranges if requested\n",
    "    if shared_axes:\n",
    "        all_x = np.concatenate([r[:, 0] for r in all_reduced])\n",
    "        all_y = np.concatenate([r[:, 1] for r in all_reduced])\n",
    "        x_min, x_max = all_x.min(), all_x.max()\n",
    "        y_min, y_max = all_y.min(), all_y.max()\n",
    "        # Add small padding (5%)\n",
    "        x_padding = (x_max - x_min) * 0.05\n",
    "        y_padding = (y_max - y_min) * 0.05\n",
    "        x_range = [x_min - x_padding, x_max + x_padding]\n",
    "        y_range = [y_min - y_padding, y_max + y_padding]\n",
    "\n",
    "    # Second pass: create plots\n",
    "    for i, (reduced, model_name, explained_var) in enumerate(\n",
    "        zip(all_reduced, model_names, all_explained_vars)\n",
    "    ):\n",
    "        # Prepare subtitle with explained variance\n",
    "        if explained_var is not None:\n",
    "            subtitle_suffix = f\"<br>(Explained var: {explained_var:.1%})\"\n",
    "        else:\n",
    "            subtitle_suffix = \"\"\n",
    "\n",
    "        # Prepare hover text\n",
    "        if quotes is not None:\n",
    "            hover_text = [\n",
    "                f\"Quote: {q[:100]}...\" if len(q) > 100 else f\"Quote: {q}\"\n",
    "                for q in quotes\n",
    "            ]\n",
    "        else:\n",
    "            hover_text = None\n",
    "\n",
    "        # Add scatter trace\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=reduced[:, 0],\n",
    "                y=reduced[:, 1],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=5, opacity=0.6, color=px.colors.qualitative.Set2[i]),\n",
    "                text=hover_text,\n",
    "                hovertemplate=\"%{text}<br>x: %{x:.3f}<br>y: %{y:.3f}<extra></extra>\",\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=1,\n",
    "            col=i + 1,\n",
    "        )\n",
    "\n",
    "        # Update subplot title with explained variance and font\n",
    "        fig.layout.annotations[i].update(\n",
    "            text=model_name + subtitle_suffix,\n",
    "            font=dict(family=\"Arial, sans-serif\", size=14),\n",
    "        )\n",
    "\n",
    "        # Set axis ranges\n",
    "        if shared_axes:\n",
    "            fig.update_xaxes(range=x_range, row=1, col=i + 1)\n",
    "            fig.update_yaxes(range=y_range, row=1, col=i + 1)\n",
    "\n",
    "    method_name = \"PCA\" if method.lower() == \"pca\" else \"t-SNE\"\n",
    "    axes_note = \" (Shared Axes)\" if shared_axes else \" (Independent Axes)\"\n",
    "\n",
    "    # Make title bold and centered, set Arial font, and increase resolution\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            \"text\": f\"<b>Separate {method_name} per Model{axes_note}</b>\",\n",
    "            \"x\": 0.5,\n",
    "            \"xanchor\": \"center\",\n",
    "            \"font\": {\"size\": 18, \"family\": \"Arial, sans-serif\"},\n",
    "        },\n",
    "        font={\"family\": \"Arial, sans-serif\", \"size\": 12},\n",
    "        width=1600,\n",
    "        height=400,\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    # Show with high resolution\n",
    "    fig.show(config={\"toImageButtonOptions\": {\"format\": \"png\", \"scale\": 3}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tj8hy693t7p",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embeddings from all three models\n",
    "embeddings_google = load_embeddings(\"embeddings/google-embedding-gemma-300m-512.npy\")\n",
    "embeddings_qwen = load_embeddings(\"embeddings/qwen-qwen3-embedding-0.6b-512.npy\")\n",
    "embeddings_ibm = load_embeddings(\n",
    "    \"embeddings/ibm-granite-embedding-125m-english-512.npy\"\n",
    ")\n",
    "embeddings_tencent = load_embeddings(\"embeddings/tencentbac-conan-embedding-v1-512.npy\")\n",
    "\n",
    "print(f\"Loaded embeddings:\")\n",
    "print(f\"  Google: {embeddings_google.shape}\")\n",
    "print(f\"  Qwen: {embeddings_qwen.shape}\")\n",
    "print(f\"  IBM: {embeddings_ibm.shape}\")\n",
    "print(f\"  Tencent: {embeddings_tencent.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fg5rxxq0gs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Combined visualization with normalization (PCA)\n",
    "print(\"=\" * 80)\n",
    "print(\"METHOD 1: Combined PCA with Normalization\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "visualize_multiple_embeddings_improved(\n",
    "    [embeddings_google, embeddings_qwen, embeddings_ibm, embeddings_tencent],\n",
    "    [\"Google EmbeddingGemma\", \"Qwen3 Embedding\", \"IBM Granite\", \"Tencent Conan\"],\n",
    "    quotes=quotes,\n",
    "    method=\"pca\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cy5ckixqhmv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Separate PCA per model (shows true structure of each space)\n",
    "print(\"=\" * 80)\n",
    "print(\"METHOD 2: Separate PCA per Model\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Each model gets its own PCA transformation - no cross-contamination\\n\")\n",
    "\n",
    "visualize_embeddings_separately(\n",
    "    [embeddings_google, embeddings_qwen, embeddings_ibm, embeddings_tencent],\n",
    "    [\"Google EmbeddingGemma\", \"Qwen3 Embedding\", \"IBM Granite\", \"Tencent Conan\"],\n",
    "    quotes=quotes,\n",
    "    method=\"pca\",\n",
    "    shared_axes=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lzb6gd7ta7n",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Combined t-SNE with normalization (better for local structure)\n",
    "print(\"=\" * 80)\n",
    "print(\"METHOD 3: Combined t-SNE with Normalization\")\n",
    "print(\"=\" * 80)\n",
    "print(\"t-SNE preserves local structure better than PCA\\n\")\n",
    "\n",
    "visualize_multiple_embeddings_improved(\n",
    "    [embeddings_google, embeddings_qwen, embeddings_ibm, embeddings_tencent],\n",
    "    [\"Google EmbeddingGemma\", \"Qwen3 Embedding\", \"IBM Granite\", \"Tencent Conan\"],\n",
    "    quotes=quotes,\n",
    "    method=\"tsne\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g0xvzp7o617",
   "metadata": {},
   "source": [
    "## Save Visualizations as High-Resolution PNGs\n",
    "\n",
    "Now let's save all three visualizations as PNG files for external use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z5r0t3zm8o",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_visualization_as_png(\n",
    "    embeddings_list: list[ndarray],\n",
    "    model_names: list[str],\n",
    "    quotes: list[str],\n",
    "    method: str,\n",
    "    filename: str,\n",
    "    viz_type: str = \"combined\",\n",
    "    shared_axes: bool = True,\n",
    "):\n",
    "    \"\"\"Save a visualization as a high-resolution PNG file.\n",
    "\n",
    "    Args:\n",
    "        embeddings_list (list[ndarray]): A list of embeddings to visualize.\n",
    "        model_names (list[str]): A list of model names corresponding to the embeddings.\n",
    "        quotes (list[str]): Original quote texts.\n",
    "        method (str): Dimensionality reduction method - \"pca\" or \"tsne\"\n",
    "        filename (str): Output filename (without extension)\n",
    "        viz_type (str): \"combined\" or \"separate\"\n",
    "        shared_axes (bool): If True and viz_type=\"separate\", use shared axes\n",
    "    \"\"\"\n",
    "\n",
    "    if viz_type == \"combined\":\n",
    "        # Normalize embeddings\n",
    "        normalized_embeddings = []\n",
    "        for emb in embeddings_list:\n",
    "            normalized_embeddings.append(normalize_embeddings(emb))\n",
    "\n",
    "        combined_embeddings = np.vstack(normalized_embeddings)\n",
    "\n",
    "        # Apply dimensionality reduction\n",
    "        if method.lower() == \"pca\":\n",
    "            reducer = PCA(n_components=2)\n",
    "            reduced_embeddings = reducer.fit_transform(combined_embeddings)\n",
    "            axis_labels = {\"x\": \"Principal Component 1\", \"y\": \"Principal Component 2\"}\n",
    "            title_method = \"PCA\"\n",
    "        elif method.lower() == \"tsne\":\n",
    "            reducer = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "            reduced_embeddings = reducer.fit_transform(combined_embeddings)\n",
    "            axis_labels = {\"x\": \"t-SNE Dimension 1\", \"y\": \"t-SNE Dimension 2\"}\n",
    "            title_method = \"t-SNE\"\n",
    "\n",
    "        df = pd.DataFrame(reduced_embeddings, columns=[\"dim1\", \"dim2\"])\n",
    "        df[\"Model\"] = np.repeat(model_names, [emb.shape[0] for emb in embeddings_list])\n",
    "        all_quotes = quotes * len(embeddings_list)\n",
    "        df[\"Quote\"] = all_quotes\n",
    "\n",
    "        fig = px.scatter(\n",
    "            df,\n",
    "            x=\"dim1\",\n",
    "            y=\"dim2\",\n",
    "            color=\"Model\",\n",
    "            color_discrete_sequence=px.colors.qualitative.Vivid,\n",
    "            labels={\"dim1\": axis_labels[\"x\"], \"dim2\": axis_labels[\"y\"]},\n",
    "            hover_data={\"Quote\": True, \"Model\": True, \"dim1\": \":.3f\", \"dim2\": \":.3f\"},\n",
    "        )\n",
    "\n",
    "        fig.update_traces(marker=dict(size=6, opacity=0.7))\n",
    "        fig.update_layout(\n",
    "            title={\n",
    "                \"text\": f\"<b>2D Visualization of Embeddings ({title_method}, Normalized)</b>\",\n",
    "                \"x\": 0.5,\n",
    "                \"xanchor\": \"center\",\n",
    "                \"font\": {\"size\": 18, \"family\": \"Arial, sans-serif\"},\n",
    "            },\n",
    "            font={\"family\": \"Arial, sans-serif\", \"size\": 12},\n",
    "            width=1200,\n",
    "            height=600,\n",
    "        )\n",
    "\n",
    "    else:  # separate\n",
    "        n_models = len(embeddings_list)\n",
    "        fig = make_subplots(\n",
    "            rows=1, cols=n_models, subplot_titles=model_names, horizontal_spacing=0.1\n",
    "        )\n",
    "\n",
    "        # Compute all reductions\n",
    "        all_reduced = []\n",
    "        all_explained_vars = []\n",
    "\n",
    "        for embeddings in embeddings_list:\n",
    "            if method.lower() == \"pca\":\n",
    "                reducer = PCA(n_components=2)\n",
    "                reduced = reducer.fit_transform(embeddings)\n",
    "                explained_var = reducer.explained_variance_ratio_.sum()\n",
    "                all_explained_vars.append(explained_var)\n",
    "            elif method.lower() == \"tsne\":\n",
    "                reducer = TSNE(n_components=2, random_state=42)\n",
    "                reduced = reducer.fit_transform(embeddings)\n",
    "                all_explained_vars.append(None)\n",
    "\n",
    "            all_reduced.append(reduced)\n",
    "\n",
    "        # Compute shared axis ranges if requested\n",
    "        if shared_axes:\n",
    "            all_x = np.concatenate([r[:, 0] for r in all_reduced])\n",
    "            all_y = np.concatenate([r[:, 1] for r in all_reduced])\n",
    "            x_min, x_max = all_x.min(), all_x.max()\n",
    "            y_min, y_max = all_y.min(), all_y.max()\n",
    "            x_padding = (x_max - x_min) * 0.05\n",
    "            y_padding = (y_max - y_min) * 0.05\n",
    "            x_range = [x_min - x_padding, x_max + x_padding]\n",
    "            y_range = [y_min - y_padding, y_max + y_padding]\n",
    "\n",
    "        # Create plots\n",
    "        for i, (reduced, model_name, explained_var) in enumerate(\n",
    "            zip(all_reduced, model_names, all_explained_vars)\n",
    "        ):\n",
    "            if explained_var is not None:\n",
    "                subtitle_suffix = f\"<br>(Explained var: {explained_var:.1%})\"\n",
    "            else:\n",
    "                subtitle_suffix = \"\"\n",
    "\n",
    "            hover_text = [\n",
    "                f\"Quote: {q[:100]}...\" if len(q) > 100 else f\"Quote: {q}\"\n",
    "                for q in quotes\n",
    "            ]\n",
    "\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=reduced[:, 0],\n",
    "                    y=reduced[:, 1],\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(size=5, opacity=0.6),\n",
    "                    text=hover_text,\n",
    "                    hovertemplate=\"%{text}<br>x: %{x:.3f}<br>y: %{y:.3f}<extra></extra>\",\n",
    "                    showlegend=False,\n",
    "                ),\n",
    "                row=1,\n",
    "                col=i + 1,\n",
    "            )\n",
    "\n",
    "            fig.layout.annotations[i].update(\n",
    "                text=model_name + subtitle_suffix,\n",
    "                font=dict(family=\"Arial, sans-serif\", size=14),\n",
    "            )\n",
    "\n",
    "            if shared_axes:\n",
    "                fig.update_xaxes(range=x_range, row=1, col=i + 1)\n",
    "                fig.update_yaxes(range=y_range, row=1, col=i + 1)\n",
    "\n",
    "        method_name = \"PCA\" if method.lower() == \"pca\" else \"t-SNE\"\n",
    "        axes_note = \" (Shared Axes)\" if shared_axes else \" (Independent Axes)\"\n",
    "\n",
    "        fig.update_layout(\n",
    "            title={\n",
    "                \"text\": f\"<b>Separate {method_name} per Model{axes_note}</b>\",\n",
    "                \"x\": 0.5,\n",
    "                \"xanchor\": \"center\",\n",
    "                \"font\": {\"size\": 18, \"family\": \"Arial, sans-serif\"},\n",
    "            },\n",
    "            font={\"family\": \"Arial, sans-serif\", \"size\": 12},\n",
    "            width=1200,\n",
    "            height=425,\n",
    "            showlegend=False,\n",
    "        )\n",
    "\n",
    "    # Save as PNG with high resolution (scale=3 means 3x the size)\n",
    "    output_path = f\"visualizations/{filename}.png\"\n",
    "    os.makedirs(\"visualizations\", exist_ok=True)\n",
    "    fig.write_image(output_path, scale=3)\n",
    "    print(f\"Saved: {output_path}\")\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0yib0kwievi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all three visualizations as high-resolution PNGs\n",
    "print(\"Saving visualizations to the 'visualizations' folder...\\n\")\n",
    "\n",
    "# 1. Combined PCA with normalization\n",
    "print(\"1. Combined PCA (Normalized)...\")\n",
    "save_visualization_as_png(\n",
    "    [embeddings_google, embeddings_qwen, embeddings_ibm, embeddings_tencent],\n",
    "    [\"Google EmbeddingGemma\", \"Qwen3 Embedding\", \"IBM Granite\", \"Tencent Conan\"],\n",
    "    quotes,\n",
    "    method=\"pca\",\n",
    "    filename=\"combined_pca_normalized\",\n",
    "    viz_type=\"combined\",\n",
    ")\n",
    "\n",
    "# 2. Separate PCA per model (with shared axes)\n",
    "print(\"\\n2. Separate PCA per Model (Shared Axes)...\")\n",
    "save_visualization_as_png(\n",
    "    [embeddings_google, embeddings_qwen, embeddings_ibm, embeddings_tencent],\n",
    "    [\"Google EmbeddingGemma\", \"Qwen3 Embedding\", \"IBM Granite\", \"Tencent Conan\"],\n",
    "    quotes,\n",
    "    method=\"pca\",\n",
    "    filename=\"separate_pca_shared_axes\",\n",
    "    viz_type=\"separate\",\n",
    "    shared_axes=False,\n",
    ")\n",
    "\n",
    "# 3. Combined t-SNE with normalization\n",
    "print(\"\\n3. Combined t-SNE (Normalized)...\")\n",
    "save_visualization_as_png(\n",
    "    [embeddings_google, embeddings_qwen, embeddings_ibm, embeddings_tencent],\n",
    "    [\"Google EmbeddingGemma\", \"Qwen3 Embedding\", \"IBM Granite\", \"Tencent Conan\"],\n",
    "    quotes,\n",
    "    method=\"tsne\",\n",
    "    filename=\"combined_tsne_normalized\",\n",
    "    viz_type=\"combined\",\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"All visualizations saved successfully!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nOutput files:\")\n",
    "print(\"  - visualizations/combined_pca_normalized.png\")\n",
    "print(\"  - visualizations/separate_pca_shared_axes.png\")\n",
    "print(\"  - visualizations/combined_tsne_normalized.png\")\n",
    "print(\"\\nAll images are saved at 3x resolution for high quality.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42bed03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
